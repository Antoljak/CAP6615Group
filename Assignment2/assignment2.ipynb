{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b96846",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import figure\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tick\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class MLP1(nn.Module):\n",
    "  '''\n",
    "    Multilayer Perceptron.\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(256, 128),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(128, 128),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(128, 256),\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)\n",
    "\n",
    "class MLP2(nn.Module):\n",
    "  '''\n",
    "    Multilayer Perceptron.\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      #nn.Linear(4096,1024),\n",
    "      #nn.Sigmoid(),\n",
    "      nn.Linear(1024, 1024),\n",
    "      nn.Sigmoid(),\n",
    "      nn.Linear(1024,512),\n",
    "      nn.Tanh(),\n",
    "      nn.Linear(512,256),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(256,128),\n",
    "      nn.LeakyReLU(),\n",
    "      nn.Linear(128,256),\n",
    "      nn.Sigmoid(),\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)\n",
    "\n",
    "def add_noise(outputVector,noise_percent,stdev):\n",
    "    '''\n",
    "    Add noise to the output vector.\n",
    "    '''\n",
    "    mean = 0\n",
    "    noise = np.random.normal(mean,stdev,outputVector.shape) * noise_percent\n",
    "    return outputVector + noise\n",
    "\n",
    "def Noisy_Testing(stdev, testRounds, noiseCrossSection, inputImageVectors, outputVector, part2=False):\n",
    "    '''\n",
    "    Test the DNN with noise.\n",
    "    '''\n",
    "    tableObject = {}\n",
    "    plotObject = {'fh': [], 'ffa': []}\n",
    "    noisySetDisplayArray=[[0]*2*len(stdev) for i in range(testRounds)]\n",
    "\n",
    "    for i in range(len(stdev)):\n",
    "        tableObject['std_'+ str(stdev[i]) + '_fh'] = []\n",
    "        tableObject['std_'+ str(stdev[i]) + '_ffa'] = []\n",
    "\n",
    "    for j in range(len(stdev)):  \n",
    "        for k in range(testRounds) :\n",
    "            corruptedVector = add_noise(inputImageVectors[k],noiseCrossSection,stdev[j])\n",
    "            noisySetDisplayArray[k][2*j] = getPredictedImage(corruptedVector) \n",
    "            testPrediction = model(torch.from_numpy(corruptedVector.astype('float32'))).detach().numpy()\n",
    "            # if(k == 0):\n",
    "            #     print(\"Noisy Input\",corruptedVector)\n",
    "            #     print(\"Noisy Output\", testPrediction)\n",
    "            for l in range(256):\n",
    "                if testPrediction[l] > 0.01:\n",
    "                    testPrediction[l] = 1\n",
    "                else:\n",
    "                    testPrediction[l] = 0\n",
    "            noisySetDisplayArray[k][(2*j)+1] = getPredictedImage(testPrediction)\n",
    "            fh,ffa = calculate_performance_metrics(outputVector[k],testPrediction)\n",
    "            # plt.figure()\n",
    "            # plt.imshow(np.reshape(outputVector[k],[16,16]))\n",
    "            # print(\"FH:\", fh, \"FFA:\", ffa)\n",
    "            tableObject['std_'+ str(stdev[j]) + '_fh'].append(round(fh,4))\n",
    "            plotObject['fh'].append(round(fh,2))\n",
    "            tableObject['std_'+ str(stdev[j]) + '_ffa'].append(round(ffa,4))\n",
    "            plotObject['ffa'].append(round(ffa,2))\n",
    "\n",
    "    perc = str(noiseCrossSection).split('.')\n",
    "        \n",
    "    if part2:\n",
    "        pandas.DataFrame(tableObject).to_csv('test_results2_' + str(perc[1]) + '.csv')\n",
    "        x = np.array([0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
    "                  0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
    "                  0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002,\n",
    "                  0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003,\n",
    "                  0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005,\n",
    "                  0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
    "                  0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02,\n",
    "                  0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03,\n",
    "                  0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
    "                  0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])\n",
    "    else:\n",
    "        pandas.DataFrame(tableObject).to_csv('test_results1_' + str(perc[1]) + '.csv')\n",
    "        x = np.array([\n",
    "        0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
    "        0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
    "        0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002, 0.002,\n",
    "        0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003, 0.003,\n",
    "        0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.005,\n",
    "        0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
    "        0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02, 0.02,\n",
    "        0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03,\n",
    "        0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,\n",
    "        0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,0.1])    \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "        \n",
    "    ax.scatter(x, plotObject['fh'], label=\"Fh\", marker= \"^\", color=\"orange\", s=30)\n",
    "    ax.scatter(x, plotObject['ffa'], label=\"Ffa\", marker= \"^\", color=\"red\", s=30)\n",
    "    \n",
    "    plt.ylim(0, 1)\n",
    "    ax.set_xscale('log')\n",
    "    ax.xaxis.set_major_formatter(tick.FormatStrFormatter('%g'))\n",
    "    \n",
    "    \n",
    "    plt.xlabel('Gaussian Noise Level (stdev, at ' + str(noiseCrossSection*100) + ' pct xsecn)')\n",
    "    plt.ylabel(\"$\\it{Fh}$ and $\\it{Ffa}$\")\n",
    "    plt.xticks(x)\n",
    "    plt.title('Graph of Fh and Ffa vs. Noise Standard Deviation \\n for noise-corrupted Alphanumeric Imagery (16x16 pixels) for \\n Heteroassociative Deep Neural Network')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    displayNoisyPredictions(noisySetDisplayArray,stdev,noiseCrossSection)\n",
    "\n",
    "def getPredictedImage(predictionVector):\n",
    "        '''\n",
    "        Get the predicted image.\n",
    "        '''\n",
    "        tempArray = []\n",
    "        for i in range(len(predictionVector)):\n",
    "            if predictionVector[i] < 0.0001:\n",
    "                tempArray.append((0,0,0)) \n",
    "            else:\n",
    "                tempArray.append((255,255,255))  \n",
    "        row_length = int(math.sqrt(len(predictionVector)))\n",
    "        finalImage = []\n",
    "        for i in range(0,len(tempArray),row_length):\n",
    "            finalImage.append(tempArray[i:i+(row_length-1)])\n",
    "        imageArray = np.array(finalImage, dtype=np.uint8)\n",
    "        return Image.fromarray(imageArray)\n",
    "\n",
    "def displayNoisyPredictions(predictionDataArray, stddev, noiseCrossSection):\n",
    "    '''\n",
    "    Display the training predictions.\n",
    "    '''\n",
    "    f,axisArray = plt.subplots(len(predictionDataArray),len(predictionDataArray[0]),figsize=(30,30))\n",
    "    plt.suptitle('DNN Noisy Set performance with Noise Cross section '+ str(int(noiseCrossSection*100)) + '%', fontsize = 16)\n",
    "    for i in range(len(predictionDataArray)):\n",
    "        for j in range(len(predictionDataArray[0])):\n",
    "            axisArray[i,j].axes.xaxis.set_visible(False)\n",
    "            axisArray[i,j].axes.yaxis.set_visible(False)\n",
    "            if j % 2 == 0:\n",
    "                axisArray[i,j].set_title('Std. dev '+str(stddev[int(j/2)]), fontsize=9,x =0.5,y = 0.9)\n",
    "            else:\n",
    "                axisArray[i,j].set_title('Output', fontsize=9, x =0.5,y = 0.9)\n",
    "            axisArray[i,j].imshow(predictionDataArray[i][j])\n",
    "\n",
    "def Create_Image_Set(filename, ASL):\n",
    "    ImageVectors = []\n",
    "    if filename!='ASL32x' and filename!='ASL64x' and ASL==False: #set1 and set2\n",
    "        for i in range(10):\n",
    "            path = os.path.join(os.path.dirname(os.path.abspath(sys.argv[1])),filename, str(i) +'.png')\n",
    "            im = Image.open(path, 'r')\n",
    "            gray = im.convert('L')\n",
    "            bw = gray.point(lambda x: 0 if x<135 else 1, '1')\n",
    "            ImageVectors.append(np.array(list(bw.getdata())))\n",
    "        for i in range(26):\n",
    "            x = i + 65\n",
    "            path = os.path.join(os.path.dirname(os.path.abspath(sys.argv[1])),filename, chr(i + 65) +'.png')\n",
    "            im = Image.open(path, 'r')\n",
    "            gray = im.convert('L')\n",
    "            bw = gray.point(lambda x: 0 if x<135 else 1, '1')\n",
    "            ImageVectors.append(np.array(list(bw.getdata())))\n",
    "    \n",
    "    elif (filename=='ASL32x' or filename=='ASL64x') and ASL==False: #set3\n",
    "        for i in range(25):\n",
    "            threshold = 0\n",
    "            if i==1 or i==2 or i==3 or i==5 or i==6 or i==7 or i==8 or i==9 or i==10 or i==12 or i==13 or i==14 or i==15 or i==16:\n",
    "                threshold=210\n",
    "            elif i==18:\n",
    "                threshold=210\n",
    "            else:\n",
    "                threshold=219\n",
    "            if i!=9:\n",
    "                path = os.path.join(os.path.dirname(os.path.abspath(sys.argv[1])),filename, chr(i + 65) +'.png')\n",
    "                im = Image.open(path, 'r')\n",
    "                gray = im.convert('L')\n",
    "                bw = gray.point(lambda x: 0 if x<threshold else 1, '1')\n",
    "                #plt.figure()\n",
    "                #plt.imshow(bw)\n",
    "                ImageVectors.append(np.array(list(bw.getdata())))\n",
    "    \n",
    "    elif ASL==True: #set1mod\n",
    "        for i in range(25):\n",
    "            if i!=9:\n",
    "                path = os.path.join(os.path.dirname(os.path.abspath(sys.argv[1])),filename, chr(i + 65) +'.png')\n",
    "                im = Image.open(path, 'r')\n",
    "                gray = im.convert('L')\n",
    "                bw = gray.point(lambda x: 0 if x<135 else 1, '1')\n",
    "                ImageVectors.append(np.array(list(bw.getdata())))\n",
    "\n",
    "    return np.array(ImageVectors)\n",
    "\n",
    "set1 = Create_Image_Set('characters1',False)\n",
    "set2 = Create_Image_Set('characters2',False)\n",
    "set3 = Create_Image_Set('ASL32x',False)\n",
    "#set3 = Create_Image_Set('ASL64x',False)\n",
    "set1mod = Create_Image_Set('characters1',True)\n",
    "\n",
    "imageTensor = torch.Tensor(set1)\n",
    "_dataSet = TensorDataset(imageTensor, imageTensor)\n",
    "_dataLoader = DataLoader(_dataSet)\n",
    "\n",
    "model = MLP1()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(10):\n",
    "    losses = []\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(_dataLoader):\n",
    "\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "    \n",
    "def calculate_performance_metrics(inputVector, outputVector):\n",
    "    totalBlackPixelCount = sum(x == 0 for x in inputVector)\n",
    "    totalWhitePixelCount = sum(x == 1 for x in inputVector)\n",
    "    wrongBlackPixelCount = 0\n",
    "    rightBlackPixelCount = 0\n",
    "    \n",
    "    for i in range(256):\n",
    "        if outputVector[i] < 0.0001:\n",
    "            if  abs(outputVector[i] - inputVector[i]) < 0.0001:\n",
    "                rightBlackPixelCount += 1\n",
    "            else:\n",
    "                wrongBlackPixelCount += 1\n",
    "    fh = rightBlackPixelCount/totalBlackPixelCount\n",
    "    ffa = wrongBlackPixelCount/totalWhitePixelCount\n",
    "    return fh, ffa\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "stdev = [0,0.001, 0.002, 0.003, 0.005, 0.01, 0.02, 0.03, 0.05,0.1]\n",
    "\n",
    "print(\"\\n------PART 1-------\\n\")\n",
    "print(\"\\nChecking accuracy on Training Set\\n\")\n",
    "\n",
    "tableObject = {}\n",
    "plotObject = {'_fh_plot': [], '_ffa_plot': []}\n",
    "\n",
    "for i in range(len(stdev)):\n",
    "        tableObject['std_'+ str(stdev[i]) + '_fh'] = []\n",
    "        tableObject['std_'+ str(stdev[i]) + '_ffa'] = []\n",
    "\n",
    "for k in range(len(stdev)):\n",
    "    for i in range(36):\n",
    "        output = model(torch.from_numpy(set1[i].astype('float32'))).detach().numpy()\n",
    "        for j in range(256):\n",
    "            if output[j] > 0:\n",
    "                output[j] = 1\n",
    "            else:\n",
    "                output[j] = 0\n",
    "        fh, ffa = calculate_performance_metrics(set1[i], output)\n",
    "        # print(\"FH:\", fh, \"FFA:\", ffa)\n",
    "        tableObject['std_'+ str(stdev[k]) + '_fh'].append(round(fh,4))\n",
    "        plotObject['_fh_plot'].append(round(fh,4))\n",
    "        tableObject['std_'+ str(stdev[k]) + '_ffa'].append(round(ffa,4))\n",
    "        plotObject['_ffa_plot'].append(round(ffa,4))\n",
    "\n",
    "pandas.DataFrame(tableObject).to_csv('test_results1_ds1_noiseless.csv')\n",
    "\n",
    "f,axis = plt.subplots(figsize=(10,8))\n",
    "axis.scatter(x=plotObject['_ffa_plot'],y=plotObject['_fh_plot'],marker=\"^\")\n",
    "axis.set_xlabel('Ffa -->')\n",
    "axis.set_ylabel('Fh -->')\n",
    "axis.set_title('Plot of Fh vs. Ffa for Training Set with optimized weights')\n",
    "\n",
    "print(\"\\nChecking accuracy on Test Set\\n\")\n",
    "\n",
    "plotObject2 = {'_fh_plot': [], '_ffa_plot': []}\n",
    "\n",
    "tableObject = {}\n",
    "\n",
    "for i in range(len(stdev)):\n",
    "        tableObject['std_'+ str(stdev[i]) + '_fh'] = []\n",
    "        tableObject['std_'+ str(stdev[i]) + '_ffa'] = []\n",
    "\n",
    "for k in range(len(stdev)):\n",
    "    for i in range(36):\n",
    "        output = model(torch.from_numpy(set2[i].astype('float32'))).detach().numpy()\n",
    "        for j in range(256):\n",
    "            if output[j] > 0:\n",
    "                output[j] = 1\n",
    "            else:\n",
    "                output[j] = 0\n",
    "        fh, ffa = calculate_performance_metrics(set2[i], output)\n",
    "        # print(\"FH:\", fh, \"FFA:\", ffa)\n",
    "        tableObject['std_'+ str(stdev[k]) + '_fh'].append(round(fh,4))\n",
    "        plotObject2['_fh_plot'].append(round(fh,4))\n",
    "        tableObject['std_'+ str(stdev[k]) + '_ffa'].append(round(ffa,4))\n",
    "        plotObject2['_ffa_plot'].append(round(ffa,4))\n",
    "\n",
    "pandas.DataFrame(tableObject).to_csv('test_results1_ds2_noiseless.csv')\n",
    "\n",
    "f,axis = plt.subplots(figsize=(10,8))\n",
    "axis.scatter(x=plotObject2['_ffa_plot'],y=plotObject2['_fh_plot'],marker=\"^\")\n",
    "axis.set_xlabel('Ffa -->')\n",
    "axis.set_ylabel('Fh -->')\n",
    "axis.set_title('Plot of Fh vs. Ffa for Testing Set with optimized weights')\n",
    "\n",
    "\n",
    "print(\"\\nNOISY\\n\")\n",
    "\n",
    "Noisy_Testing(stdev, 36,0.1, set2,set2)\n",
    "Noisy_Testing(stdev, 36,0.2, set2,set2)\n",
    "Noisy_Testing(stdev, 36, 0.25, set2, set2)\n",
    "Noisy_Testing(stdev, 36, 0.3, set2, set2)\n",
    "Noisy_Testing(stdev, 36, 0.35, set2, set2)\n",
    "\n",
    "print(\"\\n-------PART 2--------\\n\")\n",
    "imageTensor = torch.Tensor(set3)\n",
    "resultTensor = torch.Tensor(set1mod)\n",
    "_dataSet = TensorDataset(imageTensor, resultTensor)\n",
    "_dataLoader = DataLoader(_dataSet,batch_size=2)\n",
    "\n",
    "model = MLP2()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(100):\n",
    "    losses = []\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(_dataLoader):\n",
    "\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "        #print(\"Loss at this epoch: \",loss.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "\n",
    "tableObject = {}\n",
    "\n",
    "for i in range(len(stdev)):\n",
    "        tableObject['std_'+ str(stdev[i]) + '_fh'] = []\n",
    "        tableObject['std_'+ str(stdev[i]) + '_ffa'] = []\n",
    "\n",
    "plotObject3 = {'_fh_plot': [], '_ffa_plot': []}\n",
    "\n",
    "for k in range(len(stdev)):\n",
    "    for i in range(24):\n",
    "        output = model(torch.from_numpy(set3[i].astype('float32'))).detach().numpy()\n",
    "        #print(\"Output: \",output,\" Input: \",set3[i])\n",
    "        for j in range(256):\n",
    "            if output[j] > 0.01:\n",
    "                output[j] = 1\n",
    "            else:\n",
    "                output[j] = 0\n",
    "        fh, ffa = calculate_performance_metrics(set1mod[i], output)\n",
    "        #plt.figure()\n",
    "        #plt.imshow(np.reshape(output,[16,16]))\n",
    "        # print(\"FH:\", fh, \"FFA:\", ffa)\n",
    "        tableObject['std_'+ str(stdev[k]) + '_fh'].append(round(fh,4))\n",
    "        plotObject3['_fh_plot'].append(round(fh,4))\n",
    "        tableObject['std_'+ str(stdev[k]) + '_ffa'].append(round(ffa,4))\n",
    "        plotObject3['_ffa_plot'].append(round(ffa,4))\n",
    "\n",
    "pandas.DataFrame(tableObject).to_csv('test_results2_noiseless.csv')\n",
    "\n",
    "f,axis = plt.subplots(figsize=(10,8))\n",
    "axis.scatter(x=plotObject3['_ffa_plot'],y=plotObject3['_fh_plot'],marker=\"^\")\n",
    "axis.set_xlabel('Ffa -->')\n",
    "axis.set_ylabel('Fh -->')\n",
    "axis.set_title('Plot of Fh vs. Ffa for Set #3 with optimized weights')\n",
    "\n",
    "print(\"\\nNOISY\\n\")\n",
    "stdev = [0,0.001, 0.002, 0.003, 0.005, 0.01, 0.02, 0.03, 0.05,0.1]\n",
    "Noisy_Testing(stdev, 24, 0.1, set3, set1mod, True)\n",
    "Noisy_Testing(stdev, 24, 0.2, set3, set1mod, True)\n",
    "Noisy_Testing(stdev, 24, 0.25, set3, set1mod, True)\n",
    "Noisy_Testing(stdev, 24, 0.3, set3, set1mod, True)\n",
    "Noisy_Testing(stdev, 24, 0.35, set3, set1mod, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
