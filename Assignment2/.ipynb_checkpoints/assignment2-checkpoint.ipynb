{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "534b935f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on Training Set\n",
      "FH: 0.990990990990991 FFA: 0.1310344827586207\n",
      "FH: 0.9540229885057471 FFA: 0.22485207100591717\n",
      "FH: 0.888268156424581 FFA: 0.0\n",
      "FH: 0.8888888888888888 FFA: 0.0\n",
      "FH: 0.8417721518987342 FFA: 0.01020408163265306\n",
      "FH: 0.8571428571428571 FFA: 0.011363636363636364\n",
      "FH: 0.8901734104046243 FFA: 0.03614457831325301\n",
      "FH: 0.948905109489051 FFA: 0.025210084033613446\n",
      "FH: 0.8556701030927835 FFA: 0.06451612903225806\n",
      "FH: 0.8449197860962567 FFA: 0.014492753623188406\n",
      "FH: 0.959731543624161 FFA: 0.0\n",
      "FH: 0.8518518518518519 FFA: 0.014925373134328358\n",
      "FH: 0.9554140127388535 FFA: 0.010101010101010102\n",
      "FH: 0.9157894736842105 FFA: 0.0\n",
      "FH: 0.8348623853211009 FFA: 0.0\n",
      "FH: 0.9214659685863874 FFA: 0.0\n",
      "FH: 0.8253968253968254 FFA: 0.0\n",
      "FH: 0.8967391304347826 FFA: 0.0\n",
      "FH: 1.0 FFA: 0.08904109589041095\n",
      "FH: 0.9453125 FFA: 0.1875\n",
      "FH: 0.9608938547486033 FFA: 0.0\n",
      "FH: 0.9875 FFA: 0.010416666666666666\n",
      "FH: 0.9308755760368663 FFA: 0.07692307692307693\n",
      "FH: 0.8291457286432161 FFA: 0.0\n",
      "FH: 0.9393939393939394 FFA: 0.02197802197802198\n",
      "FH: 0.9719101123595506 FFA: 0.0\n",
      "FH: 0.9150326797385621 FFA: 0.009708737864077669\n",
      "FH: 0.914572864321608 FFA: 0.0\n",
      "FH: 0.7945945945945946 FFA: 0.0\n",
      "FH: 0.9558823529411765 FFA: 0.041666666666666664\n",
      "FH: 0.9567567567567568 FFA: 0.0\n",
      "FH: 0.9735099337748344 FFA: 0.06666666666666667\n",
      "FH: 0.9491525423728814 FFA: 0.06329113924050633\n",
      "FH: 0.9760479041916168 FFA: 0.0\n",
      "FH: 0.9924242424242424 FFA: 0.06451612903225806\n",
      "FH: 0.9090909090909091 FFA: 0.0\n",
      "Checking accuracy on Test Set\n",
      "FH: 0.9711538461538461 FFA: 0.23684210526315788\n",
      "FH: 1.0 FFA: 0.39086294416243655\n",
      "FH: 0.8461538461538461 FFA: 0.43884892086330934\n",
      "FH: 0.8625954198473282 FFA: 0.432\n",
      "FH: 0.8068181818181818 FFA: 0.3392857142857143\n",
      "FH: 0.8536585365853658 FFA: 0.42857142857142855\n",
      "FH: 0.9084507042253521 FFA: 0.34210526315789475\n",
      "FH: 0.9456521739130435 FFA: 0.2926829268292683\n",
      "FH: 0.8987341772151899 FFA: 0.3469387755102041\n",
      "FH: 0.912 FFA: 0.31297709923664124\n",
      "FH: 0.8951612903225806 FFA: 0.29545454545454547\n",
      "FH: 0.9285714285714286 FFA: 0.30392156862745096\n",
      "FH: 0.904 FFA: 0.5267175572519084\n",
      "FH: 0.8987341772151899 FFA: 0.30612244897959184\n",
      "FH: 0.9037037037037037 FFA: 0.5371900826446281\n",
      "FH: 0.905511811023622 FFA: 0.5658914728682171\n",
      "FH: 0.910958904109589 FFA: 0.4818181818181818\n",
      "FH: 0.8578947368421053 FFA: 0.30303030303030304\n",
      "FH: 0.9746835443037974 FFA: 0.327683615819209\n",
      "FH: 0.8487394957983193 FFA: 0.25547445255474455\n",
      "FH: 0.9230769230769231 FFA: 0.3103448275862069\n",
      "FH: 0.9448818897637795 FFA: 0.4883720930232558\n",
      "FH: 0.8366013071895425 FFA: 0.5339805825242718\n",
      "FH: 0.889763779527559 FFA: 0.4573643410852713\n",
      "FH: 0.9516129032258065 FFA: 0.3106060606060606\n",
      "FH: 0.9205298013245033 FFA: 0.5238095238095238\n",
      "FH: 0.8774193548387097 FFA: 0.2079207920792079\n",
      "FH: 0.8933333333333333 FFA: 0.330188679245283\n",
      "FH: 0.8853503184713376 FFA: 0.42424242424242425\n",
      "FH: 0.8796992481203008 FFA: 0.14634146341463414\n",
      "FH: 0.9702970297029703 FFA: 0.5483870967741935\n",
      "FH: 0.9326923076923077 FFA: 0.2894736842105263\n",
      "FH: 0.8484848484848485 FFA: 0.3951612903225806\n",
      "FH: 0.9185185185185185 FFA: 0.34710743801652894\n",
      "FH: 0.9338842975206612 FFA: 0.1925925925925926\n",
      "FH: 0.9333333333333333 FFA: 0.35537190082644626\n",
      "NOISY\n",
      "FH: 0.0\n",
      "FFA: 0.8896551724137931\n",
      "FH: 0.0\n",
      "FFA: 0.7159763313609467\n",
      "FH: 0.0\n",
      "FFA: 2.064935064935065\n",
      "FH: 0.0\n",
      "FFA: 1.7882352941176471\n",
      "FH: 0.0\n",
      "FFA: 1.3673469387755102\n",
      "FH: 0.0\n",
      "FFA: 1.6477272727272727\n",
      "FH: 0.0\n",
      "FFA: 1.891566265060241\n",
      "FH: 0.0\n",
      "FFA: 1.1176470588235294\n",
      "FH: 0.0\n",
      "FFA: 2.7419354838709675\n",
      "FH: 0.0\n",
      "FFA: 2.3043478260869565\n",
      "FH: 0.0\n",
      "FFA: 0.8896551724137931\n",
      "FH: 0.0\n",
      "FFA: 0.7159763313609467\n",
      "FH: 0.0\n",
      "FFA: 2.064935064935065\n",
      "FH: 0.0\n",
      "FFA: 1.7882352941176471\n",
      "FH: 0.0\n",
      "FFA: 1.3673469387755102\n",
      "FH: 0.0\n",
      "FFA: 1.6477272727272727\n",
      "FH: 0.0\n",
      "FFA: 1.891566265060241\n",
      "FH: 0.0\n",
      "FFA: 1.1176470588235294\n",
      "FH: 0.0\n",
      "FFA: 2.7419354838709675\n",
      "FH: 0.0\n",
      "FFA: 2.3043478260869565\n",
      "FH: 0.0\n",
      "FFA: 0.8896551724137931\n",
      "FH: 0.0\n",
      "FFA: 0.7159763313609467\n",
      "FH: 0.0\n",
      "FFA: 2.064935064935065\n",
      "FH: 0.0\n",
      "FFA: 1.7882352941176471\n",
      "FH: 0.0\n",
      "FFA: 1.3673469387755102\n",
      "FH: 0.0\n",
      "FFA: 1.6477272727272727\n",
      "FH: 0.0\n",
      "FFA: 1.891566265060241\n",
      "FH: 0.0\n",
      "FFA: 1.1176470588235294\n",
      "FH: 0.0\n",
      "FFA: 2.7419354838709675\n",
      "FH: 0.0\n",
      "FFA: 2.3043478260869565\n",
      "FH: 0.0\n",
      "FFA: 0.8896551724137931\n",
      "FH: 0.0\n",
      "FFA: 0.7159763313609467\n",
      "FH: 0.0\n",
      "FFA: 2.064935064935065\n",
      "FH: 0.0\n",
      "FFA: 1.7882352941176471\n",
      "FH: 0.0\n",
      "FFA: 1.3673469387755102\n",
      "FH: 0.0\n",
      "FFA: 1.6477272727272727\n",
      "FH: 0.0\n",
      "FFA: 1.891566265060241\n",
      "FH: 0.0\n",
      "FFA: 1.1176470588235294\n",
      "FH: 0.0\n",
      "FFA: 2.7419354838709675\n",
      "FH: 0.0\n",
      "FFA: 2.3043478260869565\n",
      "FH: 0.0\n",
      "FFA: 0.8896551724137931\n",
      "FH: 0.0\n",
      "FFA: 0.7159763313609467\n",
      "FH: 0.0\n",
      "FFA: 2.064935064935065\n",
      "FH: 0.0\n",
      "FFA: 1.7882352941176471\n",
      "FH: 0.0\n",
      "FFA: 1.3673469387755102\n",
      "FH: 0.0\n",
      "FFA: 1.6477272727272727\n",
      "FH: 0.0\n",
      "FFA: 1.891566265060241\n",
      "FH: 0.0\n",
      "FFA: 1.1176470588235294\n",
      "FH: 0.0\n",
      "FFA: 2.7419354838709675\n",
      "FH: 0.0\n",
      "FFA: 2.3043478260869565\n",
      "FH: 0.0\n",
      "FFA: 0.8896551724137931\n",
      "FH: 0.0\n",
      "FFA: 0.7159763313609467\n",
      "FH: 0.0\n",
      "FFA: 2.064935064935065\n",
      "FH: 0.0\n",
      "FFA: 1.7882352941176471\n",
      "FH: 0.0\n",
      "FFA: 1.3673469387755102\n",
      "FH: 0.0\n",
      "FFA: 1.6477272727272727\n",
      "FH: 0.0\n",
      "FFA: 1.891566265060241\n",
      "FH: 0.0\n",
      "FFA: 1.1176470588235294\n",
      "FH: 0.0\n",
      "FFA: 2.7419354838709675\n",
      "FH: 0.0\n",
      "FFA: 2.3043478260869565\n",
      "FH: 0.0\n",
      "FFA: 0.8896551724137931\n",
      "FH: 0.0\n",
      "FFA: 0.7159763313609467\n",
      "FH: 0.0\n",
      "FFA: 2.064935064935065\n",
      "FH: 0.0\n",
      "FFA: 1.7882352941176471\n",
      "FH: 0.0\n",
      "FFA: 1.3673469387755102\n",
      "FH: 0.0\n",
      "FFA: 1.6477272727272727\n",
      "FH: 0.0\n",
      "FFA: 1.891566265060241\n",
      "FH: 0.0\n",
      "FFA: 1.1176470588235294\n",
      "FH: 0.0\n",
      "FFA: 2.7419354838709675\n",
      "FH: 0.0\n",
      "FFA: 2.3043478260869565\n",
      "FH: 0.0\n",
      "FFA: 0.8896551724137931\n",
      "FH: 0.0\n",
      "FFA: 0.7159763313609467\n",
      "FH: 0.0\n",
      "FFA: 2.064935064935065\n",
      "FH: 0.0\n",
      "FFA: 1.7882352941176471\n",
      "FH: 0.0\n",
      "FFA: 1.3673469387755102\n",
      "FH: 0.0\n",
      "FFA: 1.6477272727272727\n",
      "FH: 0.0\n",
      "FFA: 1.891566265060241\n",
      "FH: 0.0\n",
      "FFA: 1.1176470588235294\n",
      "FH: 0.0\n",
      "FFA: 2.7419354838709675\n",
      "FH: 0.0\n",
      "FFA: 2.3043478260869565\n",
      "FH: 0.0\n",
      "FFA: 0.8896551724137931\n",
      "FH: 0.0\n",
      "FFA: 0.7159763313609467\n",
      "FH: 0.0\n",
      "FFA: 2.064935064935065\n",
      "FH: 0.0\n",
      "FFA: 1.7882352941176471\n",
      "FH: 0.0\n",
      "FFA: 1.3673469387755102\n",
      "FH: 0.0\n",
      "FFA: 1.6477272727272727\n",
      "FH: 0.0\n",
      "FFA: 1.891566265060241\n",
      "FH: 0.0\n",
      "FFA: 1.1176470588235294\n",
      "FH: 0.0\n",
      "FFA: 2.7419354838709675\n",
      "FH: 0.0\n",
      "FFA: 2.3043478260869565\n",
      "FH: 0.0\n",
      "FFA: 0.8896551724137931\n",
      "FH: 0.0\n",
      "FFA: 0.7159763313609467\n",
      "FH: 0.0\n",
      "FFA: 2.064935064935065\n",
      "FH: 0.0\n",
      "FFA: 1.7882352941176471\n",
      "FH: 0.0\n",
      "FFA: 1.3673469387755102\n",
      "FH: 0.0\n",
      "FFA: 1.6477272727272727\n",
      "FH: 0.0\n",
      "FFA: 1.891566265060241\n",
      "FH: 0.0\n",
      "FFA: 1.1176470588235294\n",
      "FH: 0.0\n",
      "FFA: 2.7419354838709675\n",
      "FH: 0.0\n",
      "FFA: 2.3043478260869565\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import figure\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tick\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class MLP(nn.Module):\n",
    "  '''\n",
    "    Multilayer Perceptron.\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "      nn.Linear(256, 128),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(128, 128),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(128, 256),\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    '''Forward pass'''\n",
    "    return self.layers(x)\n",
    "\n",
    "def predict(inputVector, weightMatrix):\n",
    "        '''\n",
    "        Predict the output of the input vector.\n",
    "        '''\n",
    "        \n",
    "        predictionVector = []\n",
    "        for i in range(len(weightMatrix)):\n",
    "            row_sum = sum(\n",
    "                (inputVector[j] * weightMatrix[j][i])\n",
    "                for j in range(len(weightMatrix[0]) - 1)\n",
    "            )\n",
    "\n",
    "            predictionVector.append(self.activation_fn(row_sum))\n",
    "           \n",
    "        return predictionVector\n",
    "\n",
    "def add_noise(outputVector,noise_percent,stdev):\n",
    "    '''\n",
    "    Add noise to the output vector.\n",
    "    '''\n",
    "    mean = 0\n",
    "    noise = np.random.normal(mean,stdev,outputVector.shape) * noise_percent\n",
    "    return outputVector + noise\n",
    "\n",
    "def Noisy_Testing(stdev, testRounds, inputImageVectors):\n",
    "    '''\n",
    "    Test the DNN with noise.\n",
    "    '''\n",
    "    tableObject = {}\n",
    "    plotObject = {'fh': [], 'ffa': []}\n",
    "\n",
    "    for i in range(len(stdev)):\n",
    "        tableObject['std_'+ str(stdev[i]) + '_fh'] = []\n",
    "        tableObject['std_'+ str(stdev[i]) + '_ffa'] = []\n",
    "\n",
    "    for j in range(len(stdev)):   \n",
    "        for k in range(testRounds) :\n",
    "            corruptedVector = add_noise(inputImageVectors[k],0.1,stdev[j]) \n",
    "            testPrediction = model(torch.from_numpy(corruptedVector.astype('float32')))\n",
    "            fh,ffa = calculate_performance_metrics(inputImageVectors[k],testPrediction.detach().numpy())\n",
    "            print(\"FH:\",fh)\n",
    "            print(\"FFA:\",ffa)\n",
    "\n",
    "ImageVectors = []\n",
    "\n",
    "for i in range(10):\n",
    "    path = os.path.join(os.path.dirname(os.path.abspath(sys.argv[1])),'characters1', str(i) +'.png')\n",
    "    im = Image.open(path, 'r')\n",
    "    gray = im.convert('L')\n",
    "    bw = gray.point(lambda x: 0 if x<135 else 1, '1')\n",
    "    ImageVectors.append(np.array(list(bw.getdata())))\n",
    "    \n",
    "for i in range(26):\n",
    "    x = i + 65\n",
    "    path = os.path.join(os.path.dirname(os.path.abspath(sys.argv[1])),'characters1', chr(i + 65) +'.png')\n",
    "    im = Image.open(path, 'r')\n",
    "    gray = im.convert('L')\n",
    "    bw = gray.point(lambda x: 0 if x<135 else 1, '1')\n",
    "    ImageVectors.append(np.array(list(bw.getdata())))\n",
    "\n",
    "set1 = np.array(ImageVectors)\n",
    "\n",
    "ImageVectors = []\n",
    "\n",
    "for i in range(10):\n",
    "    path = os.path.join(os.path.dirname(os.path.abspath(sys.argv[1])),'characters2', str(i) +'.png')\n",
    "    im = Image.open(path, 'r')\n",
    "    gray = im.convert('L')\n",
    "    bw = gray.point(lambda x: 0 if x<135 else 1, '1')\n",
    "    ImageVectors.append(np.array(list(bw.getdata())))\n",
    "    \n",
    "for i in range(26):\n",
    "    x = i + 65\n",
    "    path = os.path.join(os.path.dirname(os.path.abspath(sys.argv[1])),'characters2', chr(i + 65) +'.png')\n",
    "    im = Image.open(path, 'r')\n",
    "    gray = im.convert('L')\n",
    "    bw = gray.point(lambda x: 0 if x<135 else 1, '1')\n",
    "    ImageVectors.append(np.array(list(bw.getdata())))\n",
    "    \n",
    "set2 = np.array(ImageVectors)\n",
    "\n",
    "imageTensor = torch.Tensor(set1)\n",
    "_dataSet = TensorDataset(imageTensor, imageTensor)\n",
    "_dataLoader = DataLoader(_dataSet)\n",
    "\n",
    "model = MLP()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(10):\n",
    "    losses = []\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(_dataLoader):\n",
    "\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "    \n",
    "def calculate_performance_metrics(inputVector, outputVector):\n",
    "    totalBlackPixelCount = sum(x == 0 for x in inputVector)\n",
    "    totalWhitePixelCount = sum(x == 1 for x in inputVector)\n",
    "    wrongBlackPixelCount = 0\n",
    "    rightBlackPixelCount = 0\n",
    "    for i in range(256):\n",
    "        if outputVector[i] < 0.0001:\n",
    "            if  abs(outputVector[i] - inputVector[i]) < 0.0001:\n",
    "                rightBlackPixelCount += 1\n",
    "            else:\n",
    "                wrongBlackPixelCount += 1\n",
    "    fh = rightBlackPixelCount/totalBlackPixelCount\n",
    "    ffa = wrongBlackPixelCount/totalWhitePixelCount\n",
    "    return fh, ffa \n",
    "\n",
    "model.eval()\n",
    "print(\"Checking accuracy on Training Set\")\n",
    "for i in range(36):\n",
    "    output = model(torch.from_numpy(set1[i].astype('float32'))).detach().numpy()\n",
    "    for j in range(256):\n",
    "        if output[j] > 0:\n",
    "            output[j] = 1\n",
    "        else:\n",
    "            output[j] = 0\n",
    "    fh, ffa = calculate_performance_metrics(set1[i], output)\n",
    "    print(\"FH:\", fh, \"FFA:\", ffa)\n",
    "\n",
    "print(\"Checking accuracy on Test Set\")\n",
    "for i in range(36):\n",
    "    output = model(torch.from_numpy(set2[i].astype('float32'))).detach().numpy()\n",
    "    for j in range(256):\n",
    "        if output[j] > 0:\n",
    "            output[j] = 1\n",
    "        else:\n",
    "            output[j] = 0\n",
    "    fh, ffa = calculate_performance_metrics(set2[i], output)\n",
    "    print(\"FH:\", fh, \"FFA:\", ffa)\n",
    "print(\"NOISY\")\n",
    "stdev = [0,0.001, 0.002, 0.003, 0.005, 0.01, 0.02, 0.03, 0.05,0.1]\n",
    "Noisy_Testing(stdev, 10, set1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0def2cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd678d16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
