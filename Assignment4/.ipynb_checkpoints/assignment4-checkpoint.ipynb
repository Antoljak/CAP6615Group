{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Select S&P500 Dataset and Schiller P/E-10 Dataset from the URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import color\n",
    "from skimage.transform import rescale, resize,downscale_local_mean\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"Data of S&P 500\")\n",
    "dataframe = pd.read_csv(\"HistoricalData_1648610849582.csv\")\n",
    "print(dataframe)\n",
    "print(\"Data of PE Ration\")\n",
    "data_pe = pd.read_csv('S&P500 Schiller PE ratio.csv')\n",
    "print(data_pe)\n",
    "test=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Develop and test/verify a correlation-based algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_pe = data_pe[[\"DateTime\"]].to_numpy(dtype = \"str\")\n",
    "date_sp = dataframe[[\"Date\"]].to_numpy(dtype = \"str\")\n",
    "\n",
    "date_pe = np.flip(date_pe)\n",
    "date_sp = np.flip(date_sp)\n",
    "\n",
    "\n",
    "ratio_sp = data_pe['SP500PERatio'].to_numpy(dtype = 'float')\n",
    "mean_sp = ratio_sp.mean()\n",
    "max_sp = ratio_sp.max()\n",
    "median_sp = np.median(ratio_sp)\n",
    "print(mean_sp)\n",
    "print(max_sp)\n",
    "print(median_sp)\n",
    "\n",
    "sp_index = dataframe[[\"Close/Last\", \"Open\"]].to_numpy(dtype = 'float')\n",
    "mean_sp_index = sp_index[:,0].mean()\n",
    "mean_sp_index1 = sp_index[:,1].mean()\n",
    "\n",
    "print(mean_sp_index)\n",
    "print(mean_sp_index1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the data of S$P500 and PE ration\n",
    "record = []\n",
    "recordDate = []\n",
    "\n",
    "# get the date from data\n",
    "def get_date(date_data):\n",
    "    res = (date_data[:-5]).split('/')\n",
    "    if(len(res)==3):\n",
    "        return res\n",
    "    return None\n",
    "\n",
    "array_date_pe = date_pe.tolist()\n",
    "\n",
    "# if the S&P and PE in the same year and month, merge it into an item.\n",
    "\n",
    "for i in range(len(date_sp)):\n",
    "    tmp = [0 for _ in range(3)]\n",
    "    tmp[0] = sp_index[i][0]\n",
    "    record_time = str(date_sp[i][0])\n",
    "    for j in range(len(ratio_sp)):\n",
    "        peDate = get_date( array_date_pe[j][0] )\n",
    "\n",
    "        if(peDate is not None and len(peDate)==3) :\n",
    "            if(record_time[6:10]==peDate[2] ):\n",
    "                    if(peDate[1]==record_time[0:2] or ('0'+peDate[1])==record_time[0:2]):\n",
    "                        tmp[1] = ratio_sp[j]\n",
    "                        recordDate.append(record_time)\n",
    "                        record.append(tmp)\n",
    "\n",
    "dataset = np.array(record)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation scores\n",
    "\n",
    "sampleNum = 100\n",
    "for i in range(sampleNum-1 ,len(dataset)):\n",
    "    # Pearson  r\n",
    "    x = dataset[(i-sampleNum+1):(i+1), 0]\n",
    "    y = dataset[(i-sampleNum+1):(i+1), 1]\n",
    "    r = np.corrcoef(x, y)\n",
    "    dataset[i][2] = r[0,1] \n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateDigital = [];\n",
    "\n",
    "for i in range(len(recordDate)):\n",
    "    dateDigital.append(float(recordDate[i][6:10]) + ( (float(recordDate[i][0:2])-1)*30 + float(recordDate[i][3:5]) )/366 )\n",
    "\n",
    "plt.figure(figsize=(12, 6));\n",
    "plt.plot(dateDigital[(sampleNum-1):],\n",
    "         dataset[(sampleNum-1):, 2], color='grey', label='Close')\n",
    "plt.title('The Correlation of S&P 500 close price and Shiller PE Ratio in 100 days')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buy the sp when r>threshold\n",
    "money = 1\n",
    "money_all = []\n",
    "trade_all = []\n",
    "# Must buy the new stock before sell\n",
    "lastsell=0\n",
    "\n",
    "for i in range(sampleNum-1, dataset.shape[0]):\n",
    "    corr_temp = dataset[i,2]\n",
    "    price_temp = dataset[(i-sampleNum+1):(i+1), 0]\n",
    "    if corr_temp > 0.5 and (i-lastsell > sampleNum):\n",
    "        # sell at this point\n",
    "        # buy at the local minia in this window interval (nsample interval)\n",
    "        buy_price = min(price_temp)\n",
    "        # in case of the overflow\n",
    "        if buy_price > 0:           \n",
    "            sell_price = price_temp[len(price_temp)-1]\n",
    "            money = sell_price/buy_price*money\n",
    "            lastsell = i\n",
    "            print(buy_price)\n",
    "            print(sell_price)\n",
    "            print(money)\n",
    "            print(i)\n",
    "            money_all.append(money)\n",
    "            trade_all.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5));\n",
    "#plt.plot(dataframe.Date, dataframe.Open.values, color='grey', label='Open')\n",
    "# plt.plot(dataframe.Date, dataframe.Close.values, color='black', label='Close')\n",
    "#plt.plot(dataframe.Date, dataframe.Low.values, color='red', label='Low')\n",
    "#plt.plot(dataframe.Date, dataframe.High.values, color='green', label='High')\n",
    "plt.plot(dataframe.Date, dataframe[\"Close/Last\"].values, color = 'red', label='Price')\n",
    "plt.title('S&P 500 price and Shiller PE Ratio')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('S&P 500 price')\n",
    "plt.legend(loc='best')\n",
    "# twin object for two different y-axis on the sample plot\n",
    "ax2=plt.twinx()\n",
    "ax2.set_xticks(ax2.get_xticks()[::100])\n",
    "plt.xlim(-31.1,500.1)\n",
    "# make a plot with different y-axis using second axis object\n",
    "ax2.plot(data_pe.DateTime, data_pe.SP500PERatio.values,color=\"blue\")\n",
    "ax2.set_ylabel(\"Shiller PE Ratio\", color=\"blue\",fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a plot\n",
    "\n",
    "date_trade = []\n",
    "for i in range(len(trade_all)):\n",
    "    date_trade.append(recordDate[i])\n",
    "    \n",
    "plt.figure(figsize=(15, 6))\n",
    "print(len(date_trade))\n",
    "print(len(money_all))\n",
    "plt.plot(date_trade,\n",
    "         money_all, color='black', label='Close')\n",
    "plt.title('Money left at the end of trading (using correlation algorithm)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Money/millions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Design and develop a convolutional neural network (CNN) in Python that will recognize A-B-C-D-wave patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Judge if their exist a A-B-C-D wave, if exist, save it.\n",
    "sellSigIdx = []\n",
    "prev = 0\n",
    "for x in range(sampleNum-1, len(dataset)):\n",
    "    if dataset[x][2] > 0.5 and x >= prev+sampleNum//3 and \\\n",
    "    dataset[x][0] == max(dataset[(x-sampleNum+1):(x+1), 0]) and \\\n",
    "    dataset[x][0] > dataset[x+1][0]:\n",
    "        sellSigIdx.append(x)\n",
    "        prev = x\n",
    "sellSigIdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.functional as F\n",
    "import pdb\n",
    "class CNet(nn.Module):\n",
    "    def __init__(self, linear_input=60):\n",
    "        super(CNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=20,padding=2,padding_mode='replicate', kernel_size=5, stride=1)\n",
    "        self.max_pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(linear_input, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if(test==True):\n",
    "            x = x.permute(0,2,1)\n",
    "        else:\n",
    "            x = x.permute(0, 2, 1) \n",
    "#         import pdb\n",
    "#         pdb.set_trace()\n",
    "        x = self.conv1(x)\n",
    "        \n",
    "        x =  self.ReLU( self.max_pool1(x) ) \n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.ReLU(self.linear1(x))\n",
    "        x = x.unsqueeze(1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.cnn = CNet()\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.ReLU = nn.ReLU()\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "       \n",
    "        x = self.cnn(x) \n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "    \n",
    "        out = self.fc(out)\n",
    "    \n",
    "        return out[:, -1, :], hidden\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainData = dataframe[[\"Close/Last\", \"Open\",'High','Low']].to_numpy(dtype = 'float')\n",
    "targetData = dataframe[[\"Close/Last\"]].to_numpy(dtype = 'float')\n",
    "date = dataframe[[\"Date\"]].to_numpy(dtype = \"str\")\n",
    "\n",
    "norm = MinMaxScaler(feature_range = (0, 1))\n",
    "trainData = norm.fit_transform(trainData)\n",
    "targetData = norm.fit_transform(targetData)\n",
    "trainData = np.flip(trainData)\n",
    "targetData = np.flip(targetData)\n",
    "date = np.flip(date)\n",
    "dateData = []\n",
    "for i in range(date.shape[0]):\n",
    "    dateData.append(float(np.squeeze(date)[i][6:10]) + ( (float(np.squeeze(date)[i][0:2])-1)*30 + float(np.squeeze(date)[i][3:5]) )/366 )\n",
    "dateData = np.array(dateData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 6\n",
    "X = []\n",
    "Y = []\n",
    "for i in range(trainData.shape[0] - window_size - 4):\n",
    "    X.append(trainData[i:i+window_size])\n",
    "    Y.append(targetData[i+window_size:i+window_size+4])\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "Y = np.swapaxes(Y, 1, 2)\n",
    "dateAxis = dateData[:-(window_size+4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fullTraining = []\n",
    "X_training = []\n",
    "X_validation = []\n",
    "X_test = []\n",
    "Y_fullTraining = []\n",
    "Y_training = []\n",
    "Y_validation = []\n",
    "Y_test = []\n",
    "\n",
    "\n",
    "# 20% for test\n",
    "\n",
    "# For the left 80% data, 80% * 80% =64% for train, 80% * 20% = 16% for valdation \n",
    "X_fullTraining, X_test, Y_fullTraining, Y_test, date_ft, date_t = train_test_split(X, Y, dateAxis, test_size=0.2, shuffle=False)\n",
    "X_training, X_validation, Y_training, Y_validation, date_tr, date_v = train_test_split(X_fullTraining, Y_fullTraining, date_ft, test_size=0.2, shuffle=False)\n",
    "#date_test=date[438:623,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN = Model(input_size=4, output_size=4, hidden_dim=16, n_layers=1)\n",
    "optimizer = torch.optim.Adam(RNN.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTensor = torch.from_numpy(X_training).float()\n",
    "xTensor_val = torch.from_numpy(X_validation).float()\n",
    "yTensor = torch.Tensor(Y_training).float()\n",
    "yTensor_val = torch.from_numpy(Y_validation).float()\n",
    "epochs  =150\n",
    "\n",
    "record_epoch = []\n",
    "record_loss = []\n",
    "record_loss_val = []\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output, hidden = RNN(xTensor)\n",
    "    output_val, _ = RNN(xTensor_val)\n",
    "    loss = criterion(output.reshape(-1), yTensor.view(-1))\n",
    "    loss_val = criterion(output_val.reshape(-1), yTensor_val.view(-1))\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    record_epoch.append(epoch)\n",
    "    record_loss.append(loss.item())\n",
    "    record_loss_val.append(loss_val.item())\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, epochs), end=' ')\n",
    "        print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[8,6], dpi=80)\n",
    "plt.plot(np.array(record_loss), 'r', label = 'train')\n",
    "plt.plot(np.array(record_loss_val), 'b', label = 'val')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"MSEloss\")\n",
    "plt.legend()\n",
    "#plt.savefig('MSEloss_1.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Train your CNN and RNN on your Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_error(pred, actual):\n",
    "    return abs(pred - actual)/pred\n",
    "\n",
    "# Calculate the accuracy, make a plot\n",
    "def plotGraphs(output_1,output_2,output_3,output_4,Y_main,Y_plot,XAxis_date,date_pred,\n",
    "    set1_title_1,set2_title_1,set3_title_1,set4_title_1,error_title):\n",
    "    \n",
    "    table = []\n",
    "\n",
    "    error = prediction_error(output_1, Y_main)\n",
    "    error_dt = pd.DataFrame(data = error)\n",
    "    temp1 = [np.mean(error), np.std(error), error_dt.skew(axis=0).iloc[0], error_dt.kurtosis(axis=0).iloc[0]]\n",
    "    temp1 = np.array(temp1)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.set_title(set1_title_1)\n",
    "    ax1.plot(date_pred, output_1, color = 'blue', label = 'Pred')\n",
    "    ax1.plot(XAxis_date, Y_plot, color = 'green', label = 'Actual')\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.set_title(error_title)\n",
    "    ax2.plot(date_pred, error, color = 'red', label = 'Pred error')\n",
    "    ax2.legend(loc=\"upper left\")\n",
    "\n",
    "    error = prediction_error(output_2, Y_main)\n",
    "    error_dt = pd.DataFrame(data = error)\n",
    "    temp2 = [np.mean(error), np.std(error), error_dt.skew(axis=0).iloc[0], error_dt.kurtosis(axis=0).iloc[0]]\n",
    "    temp2 = np.array(temp2)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.set_title(set2_title_1)\n",
    "    ax1.plot(date_pred, output_2, color = 'blue', label = 'Pred')\n",
    "    ax1.plot(XAxis_date, Y_plot, color = 'green', label = 'Actual')\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.set_title(error_title)\n",
    "    ax2.plot(date_pred, error, color = 'red', label = 'Pred error')\n",
    "    ax2.legend(loc=\"upper left\")\n",
    "\n",
    "    error = prediction_error(output_3, Y_main)\n",
    "    error_dt = pd.DataFrame(data = error)\n",
    "    temp3 = [np.mean(error), np.std(error), error_dt.skew(axis=0).iloc[0], error_dt.kurtosis(axis=0).iloc[0]]\n",
    "    temp3 = np.array(temp3)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.set_title(set3_title_1)\n",
    "    ax1.plot(date_pred, output_3, color = 'blue', label = 'Pred')\n",
    "    ax1.plot(XAxis_date, Y_plot, color = 'green', label = 'Actual')\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.set_title(error_title)\n",
    "    ax2.plot(date_pred, error, color = 'red', label = 'Pred error')\n",
    "    ax2.legend(loc=\"upper left\")\n",
    "\n",
    "    error = prediction_error(output_4, Y_main)\n",
    "    error_dt = pd.DataFrame(data = error)\n",
    "    temp4 = [np.mean(error), np.std(error), error_dt.skew(axis=0).iloc[0], error_dt.kurtosis(axis=0).iloc[0]]\n",
    "    temp4 = np.array(temp4)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.set_title(set4_title_1)\n",
    "    ax1.plot(date_pred, output_plt4, color = 'blue', label = 'Pred')\n",
    "    ax1.plot(XAxis_date, Y_plot, color = 'green', label = 'Actual')\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.set_title(error_title)\n",
    "    ax2.plot(date_pred, error, color = 'red', label = 'Pred error')\n",
    "    ax2.legend(loc=\"upper left\")\n",
    "\n",
    "    temp1 = np.expand_dims(temp1, axis=1)\n",
    "    temp2 = np.expand_dims(temp2, axis=1)\n",
    "    temp3 = np.expand_dims(temp3, axis=1)\n",
    "    temp4 = np.expand_dims(temp4, axis=1)\n",
    "    table = np.concatenate((temp1, temp2, temp3, temp4), axis=1)\n",
    "    ind = ['Mean', 'STD-dev', 'Skewness', 'Kurtosis']\n",
    "    col = ['1 day', '2 day', '3 day', '4 day']\n",
    "    stats=pd.DataFrame(table, columns=col, index=ind).T\n",
    "    display(stats)\n",
    "\n",
    "\n",
    "def plotAccuracy(output_1,output_2,output_3,output_4,Y_main, date_pred, title_content ):\n",
    "    \n",
    "    table = []\n",
    "\n",
    "    error_1 = prediction_error(output_1, Y_main)\n",
    "    error_2 = prediction_error(output_2, Y_main)\n",
    "    error_3 = prediction_error(output_3, Y_main)\n",
    "    error_4 = prediction_error(output_4, Y_main)\n",
    "    \n",
    "    fig = plt.figure(figsize=(9, 5))\n",
    "    plt.title(title_content)\n",
    "    plt.plot(date_pred, error_1, color = 'blue', label = 't+1')\n",
    "    plt.plot(date_pred, error_2, color = 'green', label = 't+2')\n",
    "    plt.plot(date_pred, error_3, color = 'purple', label = 't+3')\n",
    "    plt.plot(date_pred, error_4, color = 'red', label = 't+4')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    \n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "#pdb.set_trace()\n",
    "output_plt = output.detach().numpy()\n",
    "\n",
    "output_plt = output_plt\n",
    "\n",
    "Y_plt = norm.inverse_transform(Y[:, :, 0])\n",
    "\n",
    "print(Y_plt.shape)\n",
    "Y_fullTrainingplt = norm.inverse_transform(Y_fullTraining[:, :, 0])\n",
    "\n",
    "output_plt1 = norm.inverse_transform(output_plt[:,0].reshape(-1,1))\n",
    "output_plt2 = norm.inverse_transform(output_plt[:,1].reshape(-1,1))\n",
    "output_plt3 = norm.inverse_transform(output_plt[:,2].reshape(-1,1))\n",
    "output_plt4 = norm.inverse_transform(output_plt[:,3].reshape(-1,1))\n",
    "\n",
    "print(output_plt1.shape)\n",
    "print(Y_training.shape)\n",
    "Y_output = Y_training[:,:,0]\n",
    "\n",
    "Y_testplt = norm.inverse_transform(Y_test[:, :, 0])\n",
    "\n",
    "#plotGraphs(output_plt1,output_plt2,output_plt3,output_plt4,Y_testplt,Y_plt,dateAxis,date_t,\n",
    "\n",
    "\n",
    "\n",
    "#import pdb\n",
    "#pdb.set_trace()\n",
    "\n",
    "plotGraphs(output_plt1,output_plt2,output_plt3,output_plt4,Y_output,Y_plt,dateAxis,date_tr,\n",
    "\"Full Training Set (1 day)\",\"Full Training Set (2 day)\",\"Full Training Set (3 day)\",\"Full Training Set (4 day)\",\"Error of Training Set\")\n",
    "\n",
    "plotAccuracy(output_plt1,output_plt2,output_plt3,output_plt4,Y_output,date_tr, 'Prediction Accuracy for price in future 1-4 days(On Train Data)' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Test your CNN and RNN accuracy over Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy, make a plot\n",
    "\n",
    "def prediction_error(pred, actual):\n",
    "    return abs(pred - actual)/pred\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN.eval()\n",
    "xTensor = torch.from_numpy(X_test).float()\n",
    "output, _ = RNN(xTensor)\n",
    "\n",
    "output_plt1 = output.detach().numpy()[:, 0]\n",
    "output_plt1 = norm.inverse_transform(output_plt1.reshape(-1,1))\n",
    "\n",
    "output_plt2 = output.detach().numpy()[:, 1]\n",
    "output_plt2 = norm.inverse_transform(output_plt2.reshape(-1,1))\n",
    "\n",
    "output_plt3 = output.detach().numpy()[:, 2]\n",
    "output_plt3 = norm.inverse_transform(output_plt3.reshape(-1,1))\n",
    "\n",
    "output_plt4 = output.detach().numpy()[:, 3]\n",
    "output_plt4 = norm.inverse_transform(output_plt4.reshape(-1,1))\n",
    "\n",
    "Y_testplt = norm.inverse_transform(Y_test[:, :, 0])\n",
    "\n",
    "plotGraphs(output_plt1,output_plt2,output_plt3,output_plt4,Y_testplt,Y_plt,dateAxis,date_t,\n",
    "\"Test Set (1 day)\",\"Test Set (2 day)\",\"Test Set (3 day)\",\"Test Set (4 day)\",\"Error of Test Set\")\n",
    "\n",
    "plotAccuracy(output_plt1,output_plt2,output_plt3,output_plt4,Y_testplt,date_t, 'Prediction Accuracy for price P in future 1-4 days(On Test Data)' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 - Optimize your CNN+RNN algorithm's performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust the parameter of the network and enhance the sliding window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4\n",
    "output_size =4\n",
    "hidden_dim = 32\n",
    "n_layers = 2\n",
    "epochs = 200\n",
    "window_size = 100\n",
    "\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "for i in range(trainData.shape[0] - window_size - 4):\n",
    "    X.append(trainData[i:i+window_size])\n",
    "    Y.append(targetData[i+window_size:i+window_size+4])\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "Y = np.swapaxes(Y, 1, 2)\n",
    "X_fullTraining = []\n",
    "X_training = []\n",
    "X_validation = []\n",
    "X_test = []\n",
    "Y_fullTraining = []\n",
    "Y_training = []\n",
    "Y_validation = []\n",
    "Y_test = []\n",
    "\n",
    "dateAxis = []\n",
    "dateData = []\n",
    "for i in range(date.shape[0]):\n",
    "    dateData.append(float(np.squeeze(date)[i][6:10]) + ( (float(np.squeeze(date)[i][0:2])-1)*30 + float(np.squeeze(date)[i][3:5]) )/366 )\n",
    "dateData = np.array(dateData)\n",
    "dateAxis = dateData[(window_size+4):]\n",
    "\n",
    "\n",
    "X_fullTraining, X_test, Y_fullTraining, Y_test, date_ft, date_t = train_test_split(X, Y, dateAxis, test_size=0.2, shuffle=False)\n",
    "X_training, X_validation, Y_training, Y_validation, date_tr, date_v = train_test_split(X_fullTraining, Y_fullTraining, date_ft, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_enhance = Model(input_size, output_size, hidden_dim, n_layers)\n",
    "RNN_enhance.cnn = CNet(50*20)\n",
    "optimizer = torch.optim.Adam(RNN_enhance.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "import pdb\n",
    "#pdb.set_trace()\n",
    "xTensor = torch.from_numpy(X_training).float()\n",
    "yTensor = torch.Tensor(Y_training).float()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output, hidden = RNN_enhance(xTensor)\n",
    "    loss = criterion(output.reshape(-1), yTensor.view(-1))\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, epochs), end=' ')\n",
    "        print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RNN_enhance.eval()\n",
    "xTensor = torch.from_numpy(X_test).float()\n",
    "output, _ = RNN_enhance(xTensor)\n",
    "\n",
    "Y_plt = norm.inverse_transform(Y[:, :, 0])\n",
    "\n",
    "output_plt1 = output.detach().numpy()[:, 0]\n",
    "output_plt1 = norm.inverse_transform(output_plt1.reshape(-1,1))\n",
    "\n",
    "output_plt2 = output.detach().numpy()[:, 1]\n",
    "output_plt2 = norm.inverse_transform(output_plt2.reshape(-1,1))\n",
    "\n",
    "output_plt3 = output.detach().numpy()[:, 2]\n",
    "output_plt3 = norm.inverse_transform(output_plt3.reshape(-1,1))\n",
    "\n",
    "output_plt4 = output.detach().numpy()[:, 3]\n",
    "output_plt4 = norm.inverse_transform(output_plt4.reshape(-1,1))\n",
    "\n",
    "Y_testplt = norm.inverse_transform(Y_test[:, :, 0])\n",
    "import pdb\n",
    "#pdb.set_trace()\n",
    "plotGraphs(output_plt1,output_plt2,output_plt3,output_plt4,Y_testplt,Y_plt,dateAxis,date_t,\n",
    "\"Test Set (1 day)\",\"Test Set (2 day)\",\"Test Set (3 day)\",\"Test Set (4 day)\",\"Error of Test Set\")\n",
    "\n",
    "plotAccuracy(output_plt1,output_plt2,output_plt3,output_plt4,Y_testplt,date_t,'Prediction Accuracy for price in future 1-4 days(Optimized )' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 - Enhance your CNN+RNN algorithm's functionality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_fullTraining.shape)\n",
    "# start with $1 m \n",
    "money = 1\n",
    "money_all = []\n",
    "trade_all = []\n",
    "price_all = []\n",
    "sampleNum = 6\n",
    "# Must buy the new stock before sell\n",
    "lastsell = -sampleNum\n",
    "\n",
    "for i in range(1,X_fullTraining.shape[0]):\n",
    "    tmp = norm.inverse_transform(X_fullTraining[i,:, :])\n",
    "    \n",
    "    prob_temp = tmp[:, 2]\n",
    "    price_temp = tmp[:, 0]\n",
    "    price_all.append(price_temp[len(price_temp)-1])\n",
    "    \n",
    "    # Sell when has high prob\n",
    "    if dataset[i][2] > 0.9 and (i-lastsell > sampleNum):\n",
    "        \n",
    "        \n",
    "        # The buy at a low PE ration\n",
    "        \n",
    "        buy_price = min(price_temp)\n",
    "        \n",
    "        if buy_price > 0:\n",
    "            sell_price = price_temp[len(price_temp)-1]\n",
    "            \n",
    "            money*= (sell_price/buy_price)\n",
    "            \n",
    "            lastsell = i\n",
    "            money_all.append(money)\n",
    "            trade_all.append(i)\n",
    "            \n",
    "            print(buy_price)\n",
    "            print(sell_price)\n",
    "            print(money)\n",
    "            print(i)\n",
    "# plt.figure(figsize=(12, 6));\n",
    "# plt.plot(dateDigital[0:1955],\n",
    "#          price_all, color='grey', label='Close')\n",
    "# plt.title('Enhanced CNN+RNN Money Return')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Money')\n",
    "df_money=pd.DataFrame(price_all, columns=dateDigital[0:1955]).T\n",
    "display(df_money)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 - Determine the Effect of Input Data Perturbations(Price Uncertainty) on your Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8a) Using your Optimized CNN+RNN algorithm (from Step 6, above) corrupt your Test Set that you used in Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noisy(dataset, threshold):\n",
    "    dataset_noise = np.ndarray(shape=dataset.shape, dtype=np.float32)\n",
    "    #set random seed \n",
    "    random.seed(2)\n",
    "    cut_nums = 4\n",
    "    for i in range(len(dataset)):\n",
    "        \n",
    "        s = np.random.normal(0, threshold, cut_nums)\n",
    "        idx = random.sample(list(range(window_size)), cut_nums)\n",
    "        dataset_noise[i] = dataset[i] \n",
    "        \n",
    "        #scale the s by the sampling window\n",
    "        s = max(X_test[1, idx, 0])*s\n",
    "        tmp = dataset_noise[i, idx, 0] + s\n",
    "        # modify the data when negative\n",
    "        tmp[tmp < 0] = 1e-7\n",
    "        dataset_noise[i, idx, 0]  = tmp\n",
    "        \n",
    "    return dataset_noise   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8b) Repeat Tests in Step 6, above, with noise-corrupted Test Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the next 1 day: idx=0 \n",
    "\n",
    "std = [0, 0.001, 0.005, 0.01, 0.02, 0.05, 0.1 ]\n",
    "\n",
    "idx = 0\n",
    "out_tmp = np.concatenate( (Y_test[:, :, idx], Y_test[:, :, idx], Y_test[:, :, idx]), axis = 1)\n",
    "target_test = norm.inverse_transform(out_tmp)[:, [0]]\n",
    "error_res_all = []\n",
    "\n",
    "for threshold in std:\n",
    "    print(threshold)\n",
    "    dataset_test_noise = add_noisy(X_test, threshold)\n",
    "    test_inputs = Variable(torch.from_numpy(dataset_test_noise).float())\n",
    "    output_test, _ = RNN_enhance(test_inputs)\n",
    "    out_tmp = np.concatenate((output_test.detach().numpy()[:, [idx]], \n",
    "                               output_test.detach().numpy()[:, [idx]],  \n",
    "                               output_test.detach().numpy()[:, [idx]]), axis=1)\n",
    "    \n",
    "    predicted_price_test = norm.inverse_transform(out_tmp)[:, [0]]\n",
    "    error = prediction_error(target_test, predicted_price_test)\n",
    "    error_res_all.append(error.reshape(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_fullTraining.shape)\n",
    "print(X_training.shape)\n",
    "print(X_validation.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8c) Repeat Step 7, above, to Determine How Much Money You Make or Lose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_fullTraining.shape)\n",
    "# start with $1 m \n",
    "money = 1\n",
    "money_all = []\n",
    "trade_all = []\n",
    "sampleNum = 6\n",
    "# Must buy the new stock before sell\n",
    "lastsell = -sampleNum\n",
    "\n",
    "for i in range(1,test_inputs.shape[0]):\n",
    "    tmp = norm.inverse_transform(test_inputs[i,:, :])\n",
    "    \n",
    "    prob_temp = tmp[:, 2]\n",
    "    price_temp = tmp[:, 0]\n",
    "    \n",
    "    # Sell when has high prob\n",
    "    if dataset[i][2] > 0.9 and (i-lastsell > sampleNum):\n",
    "        \n",
    "        \n",
    "        # The buy at a low PE ration\n",
    "        \n",
    "        buy_price = min(price_temp)\n",
    "        \n",
    "        if buy_price > 0:\n",
    "            sell_price = price_temp[len(price_temp)-1]\n",
    "            \n",
    "            money*= (sell_price/buy_price)\n",
    "            \n",
    "            lastsell = i\n",
    "            money_all.append(money)\n",
    "            trade_all.append(i)\n",
    "            \n",
    "            print(buy_price)\n",
    "            print(sell_price)\n",
    "            print(money)\n",
    "            print(i)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_img = []\n",
    "# for i in range(X_test.shape[0]):  \n",
    "#     x = X_test[i,:, 0]\n",
    "#     # make plot for the sp500 price data    \n",
    "#     plt.axis('off')\n",
    "#     plt.plot(x, color =\"grey\") \n",
    "    \n",
    "#     fig = plt.gcf()\n",
    "#     fig.set_size_inches(8, 8)\n",
    "#     fig.canvas.draw()\n",
    "       \n",
    "#     width, height = fig.get_size_inches() * fig.get_dpi()\n",
    "    \n",
    "#     mplimage = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8').reshape(576, 576, 3)\n",
    "    \n",
    "#     gray_image = color.rgb2gray(mplimage)\n",
    "#     img_resize = resize(gray_image, (180, 180),anti_aliasing=True)\n",
    "#     img_resize = img_resize.astype('float32')\n",
    "#     plt.clf()   \n",
    "#     # appending the image into the list\n",
    "#     test_img.append(img_resize)\n",
    "    \n",
    "# test_x = np.array(test_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert image format for torch\n",
    "#test_x = test_x.reshape(test_x.shape[0], 1, test_x.shape[1], test_x.shape[2])\n",
    "# test_x = test_x.reshape(test_x.shape[0], test_x.shape[1], test_x.shape[2], 1)\n",
    "# test_x = torch.from_numpy(test_x)\n",
    "# test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict sell signal\n",
    "# with torch.no_grad():\n",
    "#     test = True\n",
    "#     output,_ = RNN(test_x)\n",
    "\n",
    "# prob = torch.nn.functional.softmax(output, dim=1)\n",
    "# '''\n",
    "# if  prob > 0.5\n",
    "#       sell\n",
    "#  else:\n",
    "#       keep\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "money_res_all = []\n",
    "trade_res_all = []\n",
    "# sd = [0.001]\n",
    "# standard deviation\n",
    "sd = [0.0, 0.001, 0.002, 0.003, 0.005, 0.01, 0.02, 0.03, 0.05, 0.1]\n",
    "for sigma in sd:\n",
    "    print(sigma)\n",
    "    dataset_test_noise = add_noisy(X_test, sigma)\n",
    "    # loading images of the test dataset\n",
    "    test_img = []\n",
    "    for i in range(dataset_test_noise.shape[0]):  \n",
    "        x = dataset_test_noise[i,:, 0]\n",
    "        # function to plot the sp500 price data    \n",
    "        plt.axis('off')\n",
    "        plt.plot(x, color =\"black\") \n",
    "        figure = plt.gcf()\n",
    "        figure.set_size_inches(8, 8)\n",
    "        figure.canvas.draw()\n",
    "\n",
    "        width, height = figure.get_size_inches() * figure.get_dpi()\n",
    "        mplimage = np.frombuffer(figure.canvas.tostring_rgb(), dtype='uint8').reshape(576, 576, 3)\n",
    "        gray_image = color.rgb2gray(mplimage)\n",
    "        img_resize = resize(gray_image, (180, 180),anti_aliasing=True)\n",
    "        img_resize = img_resize.astype('float32')\n",
    "        plt.clf()   \n",
    "        # appending the image into the list\n",
    "        test_img.append(img_resize)\n",
    "\n",
    "    # converting the list to numpy array\n",
    "    test_x = np.array(test_img)\n",
    "    \n",
    "    # converting images into torch format\n",
    "    test_x = test_x.reshape(test_x.shape[0], 1, test_x.shape[1], test_x.shape[2])\n",
    "    test_x = torch.from_numpy(test_x)\n",
    "    \n",
    "    \n",
    "    # predict sell signal for whole dataset\n",
    "    with torch.no_grad():\n",
    "        output = RNN(test_x)\n",
    "\n",
    "    softmax = torch.exp(output)\n",
    "    # if prob > 0.5 then sell signal\n",
    "    # otherwise, hold \n",
    "    prob = softmax.numpy()[:,1]/np.sum(softmax.numpy(), axis = 1) \n",
    "    \n",
    "    # assuming you start with $1 million.\n",
    "    money = 1\n",
    "    money_full = []\n",
    "    trade_full = []\n",
    "    # if you haven't sell the stock, you cannot buy the new stock, in that case buypower = 0\n",
    "    lastselltime = 0\n",
    "    for i in range(1, X_test.shape[0]):\n",
    "        temp = norm.inverse_transform(X_test[i,:, :])\n",
    "        prob_temp = prob[i]\n",
    "        price_temp = temp[:, 0]\n",
    "        date_diff = date_test[i,0] - date_test[lastselltime,0]\n",
    "        days = date_diff.astype('timedelta64[D]')\n",
    "        days_diff = days / np.timedelta64(1, 'D')\n",
    "        if prob_temp > 0.9 and (days_diff > sampleNum):\n",
    "            # sell at this point\n",
    "            # buy at the local minia in this window interval\n",
    "            buy_price = min(price_temp)\n",
    "            # in case of the overflow\n",
    "            if buy_price > 0:              \n",
    "                sell_price = price_temp[len(price_temp)-1]\n",
    "                money = sell_price/buy_price*money\n",
    "                lastselltime = i\n",
    "                print(money)\n",
    "                print(i)   \n",
    "                money_full.append(money)\n",
    "                trade_full.append(i)\n",
    "                \n",
    "            \n",
    "    money_res_all.append(money_full)\n",
    "    trade_res_all.append(trade_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmaps= ['red','orange',  'yellow', 'green','blue', 'purple', 'pink', 'grey', 'brown', 'black' ]\n",
    "plt.figure(1, figsize=(12, 6))\n",
    "for i in range(len(std)):   \n",
    "    plt.plot(date_test[trade_res_all[i]], money_res_all[i] , color=cmaps[i], lw=1, label = sd[i], marker= 'o')\n",
    "    \n",
    "plt.ylabel('Money/millions')\n",
    "plt.xlabel('Time')\n",
    "\n",
    "plt.title('Money Earned for CNN+RNN Model with Noise-Corrupted Test Data <2012-2020> (Optimized)')\n",
    "plt.legend(loc=\"upper left\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9 - Modify the CNN+RNN algorithm in this assignment to generate a BUY signal as well as a SELL signal.  Then optimize your enhanced algorithm as stated in Steps 5 and 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b702ee99c54dc3b4d4b3705c725497563f4c969def566813e3a469d09f4b3fc1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
