{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa26e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "dataframe = pd.read_csv(\"SP500DATA.csv\")\n",
    "print(dataframe)# Text file data converted to integer data type\n",
    "Shillerdataframe = pd.read_csv(\"S&P500 Schiller PE ratio EC.csv\")\n",
    "#Inserting the Schiller PE ratio as a column to be considered while training the RNN\n",
    "print(Shillerdataframe[[\"SP500PERatio\"]])\n",
    "dataframe.insert(7,\"SP500PERatio\",Shillerdataframe[[\"SP500PERatio\"]])\n",
    "display(dataframe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae40abd8",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72462093",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainData = dataframe[[\"Price\", \"Open\",\"SP500PERatio\"]].to_numpy(dtype = 'float')\n",
    "targetData = dataframe[[\"Price\"]].to_numpy(dtype = 'float')\n",
    "date = dataframe[[\"Date\"]].to_numpy(dtype = \"str\")\n",
    "\n",
    "norm = MinMaxScaler(feature_range = (0, 1))\n",
    "trainData = norm.fit_transform(trainData)\n",
    "targetData = norm.fit_transform(targetData)\n",
    "trainData = np.flip(trainData)\n",
    "targetData = np.flip(targetData)\n",
    "date = np.flip(date)\n",
    "\n",
    "dateAxis = []\n",
    "for i in range(date.shape[0]):\n",
    "    dateAxis.append(float(np.squeeze(date)[i][6:10]) + float(np.squeeze(date)[i][3:5])/12.0)\n",
    "dateAxis = np.array(dateAxis)\n",
    "dateAxis_test=date[438:623,:]\n",
    "dateAxis = dateAxis[6:620]\n",
    "print(dateAxis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69ef2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i in range(trainData.shape[0] - 5 - 4):\n",
    "    X.append(trainData[i:i+6])\n",
    "    Y.append(targetData[i+6:i+6+4])\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "Y = np.swapaxes(Y, 1, 2)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f3717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fullTraining = []\n",
    "X_training = []\n",
    "X_validation = []\n",
    "X_test = []\n",
    "Y_fullTraining = []\n",
    "Y_training = []\n",
    "Y_validation = []\n",
    "Y_test = []\n",
    "\n",
    "X_fullTraining, X_test, Y_fullTraining, Y_test, date_ft, date_t = train_test_split(X, Y, dateAxis, test_size=0.3, shuffle=False)\n",
    "X_training, X_validation, Y_training, Y_validation, date_tr, date_v = train_test_split(X_fullTraining, Y_fullTraining, date_ft, test_size=0.3, shuffle=False)\n",
    "\n",
    "date_test=date[438:623,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0d326",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88ffb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "    \n",
    "        out = self.fc(out)\n",
    "    \n",
    "        return out[:, -1, :], hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68396d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN = Model(input_size=3, output_size=4, hidden_dim=16, n_layers=1)\n",
    "optimizer = torch.optim.Adam(RNN.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb8a01b",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0a44a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTensor = torch.from_numpy(X_fullTraining).float()\n",
    "yTensor = torch.Tensor(Y_fullTraining).float()\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output, hidden = RNN(xTensor)\n",
    "    loss = criterion(output.reshape(-1), yTensor.view(-1))\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, 100), end=' ')\n",
    "        print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96428f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_error(pred, actual):\n",
    "    return abs(pred - actual)/pred\n",
    "\n",
    "def plotNoiselessGraphs(output_1,output_2,output_3,output_4,Y_main,Y_plot,XAxis_date,date_pred,\n",
    "    set1_title_1,set2_title_1,set3_title_1,set4_title_1,error_title):\n",
    "    \n",
    "    table = []\n",
    "\n",
    "    error = prediction_error(output_1, Y_main)\n",
    "    error_dt = pd.DataFrame(data = error)\n",
    "    temp1 = [np.mean(error), np.std(error), error_dt.skew(axis=0).iloc[0], error_dt.kurtosis(axis=0).iloc[0]]\n",
    "    temp1 = np.array(temp1)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.set_title(set1_title_1)\n",
    "    ax1.plot(date_pred, output_1, color = 'blue', label = 'Pred')\n",
    "    ax1.plot(XAxis_date, Y_plot, color = 'green', label = 'Actual')\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.set_title(error_title)\n",
    "    ax2.plot(date_pred, error, color = 'red', label = 'Pred error')\n",
    "    ax2.legend(loc=\"upper left\")\n",
    "\n",
    "    error = prediction_error(output_2, Y_main)\n",
    "    error_dt = pd.DataFrame(data = error)\n",
    "    temp2 = [np.mean(error), np.std(error), error_dt.skew(axis=0).iloc[0], error_dt.kurtosis(axis=0).iloc[0]]\n",
    "    temp2 = np.array(temp2)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.set_title(set2_title_1)\n",
    "    ax1.plot(date_pred, output_2, color = 'blue', label = 'Pred')\n",
    "    ax1.plot(XAxis_date, Y_plot, color = 'green', label = 'Actual')\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.set_title(error_title)\n",
    "    ax2.plot(date_pred, error, color = 'red', label = 'Pred error')\n",
    "    ax2.legend(loc=\"upper left\")\n",
    "\n",
    "    error = prediction_error(output_3, Y_main)\n",
    "    error_dt = pd.DataFrame(data = error)\n",
    "    temp3 = [np.mean(error), np.std(error), error_dt.skew(axis=0).iloc[0], error_dt.kurtosis(axis=0).iloc[0]]\n",
    "    temp3 = np.array(temp3)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.set_title(set3_title_1)\n",
    "    ax1.plot(date_pred, output_3, color = 'blue', label = 'Pred')\n",
    "    ax1.plot(XAxis_date, Y_plot, color = 'green', label = 'Actual')\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.set_title(error_title)\n",
    "    ax2.plot(date_pred, error, color = 'red', label = 'Pred error')\n",
    "    ax2.legend(loc=\"upper left\")\n",
    "\n",
    "    error = prediction_error(output_4, Y_main)\n",
    "    error_dt = pd.DataFrame(data = error)\n",
    "    temp4 = [np.mean(error), np.std(error), error_dt.skew(axis=0).iloc[0], error_dt.kurtosis(axis=0).iloc[0]]\n",
    "    temp4 = np.array(temp4)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.set_title(set4_title_1)\n",
    "    ax1.plot(date_pred, output_plt4, color = 'blue', label = 'Pred')\n",
    "    ax1.plot(XAxis_date, Y_plot, color = 'green', label = 'Actual')\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.set_title(error_title)\n",
    "    ax2.plot(date_pred, error, color = 'red', label = 'Pred error')\n",
    "    ax2.legend(loc=\"upper left\")\n",
    "\n",
    "    temp1 = np.expand_dims(temp1, axis=1)\n",
    "    temp2 = np.expand_dims(temp2, axis=1)\n",
    "    temp3 = np.expand_dims(temp3, axis=1)\n",
    "    temp4 = np.expand_dims(temp4, axis=1)\n",
    "    table = np.concatenate((temp1, temp2, temp3, temp4), axis=1)\n",
    "    ind = ['Mean', 'STD-dev', 'Skewness', 'Kurtosis']\n",
    "    col = ['1 day', '2 day', '3 day', '4 day']\n",
    "    stats=pd.DataFrame(table, columns=col, index=ind).T\n",
    "    display(stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae68e7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_plt1 = output.detach().numpy()[:, 0]\n",
    "output_plt1 = norm.inverse_transform(output_plt1.reshape(-1,1))\n",
    "\n",
    "output_plt2 = output.detach().numpy()[:, 1]\n",
    "output_plt2 = norm.inverse_transform(output_plt2.reshape(-1,1))\n",
    "\n",
    "output_plt3 = output.detach().numpy()[:, 2]\n",
    "output_plt3 = norm.inverse_transform(output_plt3.reshape(-1,1))\n",
    "\n",
    "output_plt4 = output.detach().numpy()[:, 3]\n",
    "output_plt4 = norm.inverse_transform(output_plt4.reshape(-1,1))\n",
    "\n",
    "Y_plt = norm.inverse_transform(Y[:, :, 0])\n",
    "Y_fullTrainingplt = norm.inverse_transform(Y_fullTraining[:, :, 0])\n",
    "\n",
    "plotNoiselessGraphs(output_plt1,output_plt2,output_plt3,output_plt4,Y_fullTrainingplt,Y_plt,dateAxis,date_ft,\n",
    "\"Full Training Set (1 day)\",\"Full Training Set (2 day)\",\"Full Training Set (3 day)\",\"Full Training Set (4 day)\",\"Error of Training Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a864bd3f",
   "metadata": {},
   "source": [
    "# Step 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce6141",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN.eval()\n",
    "xTensor = torch.from_numpy(X_test).float()\n",
    "output, _ = RNN(xTensor)\n",
    "\n",
    "output_plt1 = output.detach().numpy()[:, 0]\n",
    "output_plt1 = norm.inverse_transform(output_plt1.reshape(-1,1))\n",
    "\n",
    "output_plt2 = output.detach().numpy()[:, 1]\n",
    "output_plt2 = norm.inverse_transform(output_plt2.reshape(-1,1))\n",
    "\n",
    "output_plt3 = output.detach().numpy()[:, 2]\n",
    "output_plt3 = norm.inverse_transform(output_plt3.reshape(-1,1))\n",
    "\n",
    "output_plt4 = output.detach().numpy()[:, 3]\n",
    "output_plt4 = norm.inverse_transform(output_plt4.reshape(-1,1))\n",
    "\n",
    "Y_testplt = norm.inverse_transform(Y_test[:, :, 0])\n",
    "\n",
    "plotNoiselessGraphs(output_plt1,output_plt2,output_plt3,output_plt4,Y_testplt,Y_plt,dateAxis,date_t,\n",
    "\"Test Set (1 day)\",\"Test Set (2 day)\",\"Test Set (3 day)\",\"Test Set (4 day)\",\"Error of Test Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deed342",
   "metadata": {},
   "source": [
    "# Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNval = Model(input_size=3, output_size=4, hidden_dim=32, n_layers=2)\n",
    "optimizerVal = torch.optim.Adam(RNNval.parameters(), lr=0.002)\n",
    "criterionVal = nn.MSELoss()\n",
    "RNNval\n",
    "\n",
    "xTensor = torch.from_numpy(X_training).float()\n",
    "yTensor = torch.Tensor(Y_training).float()\n",
    "\n",
    "for epoch in range(200):\n",
    "    optimizerVal.zero_grad()\n",
    "    \n",
    "    output, hidden = RNNval(xTensor)\n",
    "    loss = criterionVal(output.reshape(-1), yTensor.view(-1))\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizerVal.step()\n",
    "    \n",
    "    if epoch%100 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, 200), end=' ')\n",
    "        print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc5d9e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output_plt1 = output.detach().numpy()[:, 0]\n",
    "output_plt1 = norm.inverse_transform(output_plt1.reshape(-1,1))\n",
    "\n",
    "output_plt2 = output.detach().numpy()[:, 1]\n",
    "output_plt2 = norm.inverse_transform(output_plt2.reshape(-1,1))\n",
    "\n",
    "output_plt3 = output.detach().numpy()[:, 2]\n",
    "output_plt3 = norm.inverse_transform(output_plt3.reshape(-1,1))\n",
    "\n",
    "output_plt4 = output.detach().numpy()[:, 3]\n",
    "output_plt4 = norm.inverse_transform(output_plt4.reshape(-1,1))\n",
    "\n",
    "Y_plt = norm.inverse_transform(Y[:, :, 0])\n",
    "Y_trainingplt = norm.inverse_transform(Y_training[:, :, 0])\n",
    "\n",
    "plotNoiselessGraphs(output_plt1,output_plt2,output_plt3,output_plt4,Y_trainingplt,Y_plt,dateAxis,date_tr,\n",
    "\"Training Set (1 day)\",\"Training Set (2 day)\",\"Training Set (3 day)\",\"Training Set (4 day)\",\"Error of Training Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71349bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNval.eval()\n",
    "xTensor = torch.from_numpy(X_validation).float()\n",
    "output, _ = RNNval(xTensor)\n",
    "\n",
    "output_plt1 = output.detach().numpy()[:, 0]\n",
    "output_plt1 = norm.inverse_transform(output_plt1.reshape(-1,1))\n",
    "\n",
    "output_plt2 = output.detach().numpy()[:, 1]\n",
    "output_plt2 = norm.inverse_transform(output_plt2.reshape(-1,1))\n",
    "\n",
    "output_plt3 = output.detach().numpy()[:, 2]\n",
    "output_plt3 = norm.inverse_transform(output_plt3.reshape(-1,1))\n",
    "\n",
    "output_plt4 = output.detach().numpy()[:, 3]\n",
    "output_plt4 = norm.inverse_transform(output_plt4.reshape(-1,1))\n",
    "\n",
    "Y_validationplt = norm.inverse_transform(Y_validation[:, :, 0])\n",
    "\n",
    "plotNoiselessGraphs(output_plt1,output_plt2,output_plt3,output_plt4,Y_validationplt,Y_plt,dateAxis,date_v,\n",
    "\"Validation Set (1 day)\",\"Validation Set (2 day)\",\"Validation Set (3 day)\",\"Validation Set (4 day)\",\"Error of Validation Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388d7e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTensor = torch.from_numpy(X_test).float()\n",
    "output, _ = RNNval(xTensor)\n",
    "\n",
    "output_plt1 = output.detach().numpy()[:, 0]\n",
    "output_plt1 = norm.inverse_transform(output_plt1.reshape(-1,1))\n",
    "\n",
    "output_plt2 = output.detach().numpy()[:, 1]\n",
    "output_plt2 = norm.inverse_transform(output_plt2.reshape(-1,1))\n",
    "\n",
    "output_plt3 = output.detach().numpy()[:, 2]\n",
    "output_plt3 = norm.inverse_transform(output_plt3.reshape(-1,1))\n",
    "\n",
    "output_plt4 = output.detach().numpy()[:, 3]\n",
    "output_plt4 = norm.inverse_transform(output_plt4.reshape(-1,1))\n",
    "\n",
    "Y_testplt = norm.inverse_transform(Y_test[:, :, 0])\n",
    "\n",
    "plotNoiselessGraphs(output_plt1,output_plt2,output_plt3,output_plt4,Y_testplt,Y_plt,dateAxis,date_t,\n",
    "\"Test Set (1 day)\",\"Test Set (2 day)\",\"Test Set (3 day)\",\"Test Set (4 day)\",\"Error of Test Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85cc5b5",
   "metadata": {},
   "source": [
    "# Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d8ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(day_index):\n",
    "    out_temp = np.concatenate( (Y_test[:, :, day_index], Y_test[:, :, day_index], Y_test[:, :, day_index]), axis = 1)\n",
    "    target = norm.inverse_transform(out_temp)[:, [0]]\n",
    "    error_res_all = []\n",
    "    for sigma in stdev:\n",
    "        noisy_data = NoisyTesting(X_test, sigma)\n",
    "        inputs = Variable(torch.from_numpy(noisy_data).float())\n",
    "        output, _ = RNNval(inputs)\n",
    "        out_temp = np.concatenate((output.detach().numpy()[:, [day_index]], \n",
    "                                   output.detach().numpy()[:, [day_index]],  \n",
    "                                   output.detach().numpy()[:, [day_index]]), axis=1)\n",
    "        predicted_price = norm.inverse_transform(out_temp)[:, [0]]\n",
    "        error = prediction_error(target, predicted_price)\n",
    "        error_res_all.append(error.reshape(-1))\n",
    "    return error_res_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896ae08a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmaps= ['red','purple', 'green', 'orange',  'yellow', 'pink', 'grey', 'brown', 'black','blue' ]\n",
    "def FullGraphing(day):\n",
    "    plt.figure(1, figsize=(15, 5))\n",
    "    for i in range(len(stdev)): \n",
    "        #print(np.shape(date_test))\n",
    "        #print(np.shape(error_res_all[i]))\n",
    "        #print(np.shape(cmaps[i]))\n",
    "        plt.plot(np.squeeze(date_test), error_res_all[i], color=cmaps[i], lw=1, label = stdev[i], marker= 'o', linestyle='None')  \n",
    "\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Prediction error')\n",
    "    plt.title('Prediction error with Different Noise Levels (next ' +day+ ' day)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    ax2=plt.twinx()\n",
    "    ax2.set_xticks(ax2.get_xticks()[::20]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6ba8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def IndividualGraphing(day):\n",
    "    for i in range(len(stdev)): \n",
    "        plt.figure(1, figsize=(15, 5))\n",
    "        plt.plot(np.squeeze(date_test), error_res_all[i], color=cmaps[i], lw=1, label = stdev[i], marker= 'o', linestyle='None')  \n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Prediction error')\n",
    "        plt.title('Prediction error with Different Noise Levels (next '+day+' day)')\n",
    "        plt.legend(loc=\"lower right\")  \n",
    "        ax2=plt.twinx()\n",
    "        ax2.set_xticks(ax2.get_xticks()[::20])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2862315",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NOISY\")\n",
    "stdev = [0,0.001, 0.002, 0.003, 0.005, 0.01, 0.02, 0.03, 0.05,0.1]\n",
    "\n",
    "def NoisyTesting(dataset, sigma):\n",
    "    noisy_data = np.ndarray(shape=dataset.shape, dtype=np.float32)\n",
    "    #set seed for random numbers\n",
    "    random.seed(1)\n",
    "    for i in range(6):\n",
    "        s = np.random.normal(0, sigma, 20)\n",
    "        index = random.sample(list(range(180)), 20)\n",
    "        noisy_data[i] = dataset[i]\n",
    "        noisy_data[index, i, 0] = noisy_data[index, i, 0] + s\n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52906f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_res_all=predict(0)\n",
    "\n",
    "labels = date_test[:,0]\n",
    "df_error=pd.DataFrame(error_res_all, columns=labels, index=stdev).T\n",
    "display(df_error)\n",
    "\n",
    "FullGraphing(\"one\")\n",
    "IndividualGraphing(\"one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_res_all=predict(1)\n",
    "\n",
    "output.detach().numpy()[:,0:1]\n",
    "df_error=pd.DataFrame(error_res_all, columns=labels, index=stdev).T\n",
    "display(df_error)\n",
    "\n",
    "FullGraphing(\"two\")\n",
    "IndividualGraphing(\"two\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef94d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_res_all=predict(2)\n",
    "\n",
    "output.detach().numpy()[:,0:2]\n",
    "df_error=pd.DataFrame(error_res_all, columns=labels, index=stdev).T\n",
    "display(df_error)\n",
    "\n",
    "FullGraphing(\"three\")\n",
    "IndividualGraphing(\"three\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7157414",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_res_all=predict(3)\n",
    "\n",
    "output.detach().numpy()[:,0:3]\n",
    "df_error=pd.DataFrame(error_res_all, columns=labels, index=stdev).T\n",
    "display(df_error)\n",
    "\n",
    "FullGraphing(\"four\")\n",
    "IndividualGraphing(\"four\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
