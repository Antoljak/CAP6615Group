{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2bfa26e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date    Price     Open     High      Low Vol.  Change %\n",
      "0    01/12/2021  4766.18  4623.80  4808.52  4494.20    -    0.0436\n",
      "1    01/11/2021  4567.00  4616.47  4743.74  4560.26    -   -0.0083\n",
      "2    01/10/2021  4605.38  4324.71  4608.70  4278.70    -    0.0691\n",
      "3    01/09/2021  4307.54  4531.04  4544.58  4304.90    -   -0.0476\n",
      "4    01/08/2021  4522.68  4415.90  4537.80  4369.20    -    0.0290\n",
      "..          ...      ...      ...      ...      ...  ...       ...\n",
      "618  01/06/1970    72.72    76.55    79.96    72.25    -   -0.0500\n",
      "619  01/05/1970    76.55    81.52    82.32    68.61    -   -0.0610\n",
      "620  01/04/1970    81.52    89.63    90.70    79.31    -   -0.0905\n",
      "621  01/03/1970    89.63    89.50    91.07    86.19    -    0.0015\n",
      "622  01/02/1970    89.50    85.02    90.33    84.64    -    0.0527\n",
      "\n",
      "[623 rows x 7 columns]\n",
      "     SP500PERatio\n",
      "0           26.66\n",
      "1           26.61\n",
      "2           25.44\n",
      "3           25.35\n",
      "4           26.23\n",
      "..            ...\n",
      "618         13.69\n",
      "619         13.69\n",
      "620         15.37\n",
      "621         15.75\n",
      "622         15.35\n",
      "\n",
      "[623 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Vol.</th>\n",
       "      <th>Change %</th>\n",
       "      <th>SP500PERatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/12/2021</td>\n",
       "      <td>4766.18</td>\n",
       "      <td>4623.80</td>\n",
       "      <td>4808.52</td>\n",
       "      <td>4494.20</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>26.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/11/2021</td>\n",
       "      <td>4567.00</td>\n",
       "      <td>4616.47</td>\n",
       "      <td>4743.74</td>\n",
       "      <td>4560.26</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.0083</td>\n",
       "      <td>26.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/10/2021</td>\n",
       "      <td>4605.38</td>\n",
       "      <td>4324.71</td>\n",
       "      <td>4608.70</td>\n",
       "      <td>4278.70</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>25.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/09/2021</td>\n",
       "      <td>4307.54</td>\n",
       "      <td>4531.04</td>\n",
       "      <td>4544.58</td>\n",
       "      <td>4304.90</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.0476</td>\n",
       "      <td>25.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/08/2021</td>\n",
       "      <td>4522.68</td>\n",
       "      <td>4415.90</td>\n",
       "      <td>4537.80</td>\n",
       "      <td>4369.20</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>26.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>01/06/1970</td>\n",
       "      <td>72.72</td>\n",
       "      <td>76.55</td>\n",
       "      <td>79.96</td>\n",
       "      <td>72.25</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.0500</td>\n",
       "      <td>13.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>01/05/1970</td>\n",
       "      <td>76.55</td>\n",
       "      <td>81.52</td>\n",
       "      <td>82.32</td>\n",
       "      <td>68.61</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.0610</td>\n",
       "      <td>13.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>01/04/1970</td>\n",
       "      <td>81.52</td>\n",
       "      <td>89.63</td>\n",
       "      <td>90.70</td>\n",
       "      <td>79.31</td>\n",
       "      <td>-</td>\n",
       "      <td>-0.0905</td>\n",
       "      <td>15.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>01/03/1970</td>\n",
       "      <td>89.63</td>\n",
       "      <td>89.50</td>\n",
       "      <td>91.07</td>\n",
       "      <td>86.19</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>15.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>01/02/1970</td>\n",
       "      <td>89.50</td>\n",
       "      <td>85.02</td>\n",
       "      <td>90.33</td>\n",
       "      <td>84.64</td>\n",
       "      <td>-</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>15.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>623 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Price     Open     High      Low Vol.  Change %  \\\n",
       "0    01/12/2021  4766.18  4623.80  4808.52  4494.20    -    0.0436   \n",
       "1    01/11/2021  4567.00  4616.47  4743.74  4560.26    -   -0.0083   \n",
       "2    01/10/2021  4605.38  4324.71  4608.70  4278.70    -    0.0691   \n",
       "3    01/09/2021  4307.54  4531.04  4544.58  4304.90    -   -0.0476   \n",
       "4    01/08/2021  4522.68  4415.90  4537.80  4369.20    -    0.0290   \n",
       "..          ...      ...      ...      ...      ...  ...       ...   \n",
       "618  01/06/1970    72.72    76.55    79.96    72.25    -   -0.0500   \n",
       "619  01/05/1970    76.55    81.52    82.32    68.61    -   -0.0610   \n",
       "620  01/04/1970    81.52    89.63    90.70    79.31    -   -0.0905   \n",
       "621  01/03/1970    89.63    89.50    91.07    86.19    -    0.0015   \n",
       "622  01/02/1970    89.50    85.02    90.33    84.64    -    0.0527   \n",
       "\n",
       "     SP500PERatio  \n",
       "0           26.66  \n",
       "1           26.61  \n",
       "2           25.44  \n",
       "3           25.35  \n",
       "4           26.23  \n",
       "..            ...  \n",
       "618         13.69  \n",
       "619         13.69  \n",
       "620         15.37  \n",
       "621         15.75  \n",
       "622         15.35  \n",
       "\n",
       "[623 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "dataframe = pd.read_csv(\"SP500DATA.csv\")\n",
    "print(dataframe)# Text file data converted to integer data type\n",
    "Shillerdataframe = pd.read_csv(\"S&P500 Schiller PE ratio EC.csv\")\n",
    "#Inserting the Schiller PE ratio as a column to be considered while training the RNN\n",
    "print(Shillerdataframe[[\"SP500PERatio\"]])\n",
    "dataframe.insert(7,\"SP500PERatio\",Shillerdataframe[[\"SP500PERatio\"]])\n",
    "display(dataframe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae40abd8",
   "metadata": {},
   "source": [
    "# Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "72462093",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614,)\n"
     ]
    }
   ],
   "source": [
    "trainData = dataframe[[\"Price\", \"Open\",\"SP500PERatio\"]].to_numpy(dtype = 'float')\n",
    "targetData = dataframe[[\"Price\"]].to_numpy(dtype = 'float')\n",
    "date = dataframe[[\"Date\"]].to_numpy(dtype = \"str\")\n",
    "\n",
    "norm = MinMaxScaler(feature_range = (0, 1))\n",
    "trainData = norm.fit_transform(trainData)\n",
    "targetData = norm.fit_transform(targetData)\n",
    "trainData = np.flip(trainData)\n",
    "targetData = np.flip(targetData)\n",
    "date = np.flip(date)\n",
    "\n",
    "dateAxis = []\n",
    "for i in range(date.shape[0]):\n",
    "    dateAxis.append(float(np.squeeze(date)[i][6:10]) + float(np.squeeze(date)[i][3:5])/12.0)\n",
    "dateAxis = np.array(dateAxis)\n",
    "dateAxis_test=date[438:623,:]\n",
    "dateAxis = dateAxis[6:620]\n",
    "print(dateAxis.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c69ef2e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 1, 4)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i in range(trainData.shape[0] - 5 - 4):\n",
    "    X.append(trainData[i:i+6])\n",
    "    Y.append(targetData[i+6:i+6+4])\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "Y = np.swapaxes(Y, 1, 2)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "93f3717a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fullTraining = []\n",
    "X_training = []\n",
    "X_validation = []\n",
    "X_test = []\n",
    "Y_fullTraining = []\n",
    "Y_training = []\n",
    "Y_validation = []\n",
    "Y_test = []\n",
    "\n",
    "X_fullTraining, X_test, Y_fullTraining, Y_test, date_ft, date_t = train_test_split(X, Y, dateAxis, test_size=0.3, shuffle=False)\n",
    "X_training, X_validation, Y_training, Y_validation, date_tr, date_v = train_test_split(X_fullTraining, Y_fullTraining, date_ft, test_size=0.3, shuffle=False)\n",
    "\n",
    "date_test=date[438:623,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d0d326",
   "metadata": {},
   "source": [
    "# Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88ffb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "    \n",
    "        out = self.fc(out)\n",
    "    \n",
    "        return out[:, -1, :], hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68396d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (rnn): RNN(3, 16, batch_first=True)\n",
       "  (fc): Linear(in_features=16, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN = Model(input_size=3, output_size=4, hidden_dim=16, n_layers=1)\n",
    "optimizer = torch.optim.Adam(RNN.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb8a01b",
   "metadata": {},
   "source": [
    "# Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0a44a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 3, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\RAGHUN~1\\AppData\\Local\\Temp/ipykernel_9356/3255757324.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myTensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\RAGHUN~1\\AppData\\Local\\Temp/ipykernel_9356/3213402179.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mhx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m         \u001b[0m_impl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_rnn_impls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    205\u001b[0m             raise RuntimeError(\n\u001b[0;32m    206\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[1;32m--> 207\u001b[1;33m                     self.input_size, input.size(-1)))\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_expected_hidden_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 3, got 2"
     ]
    }
   ],
   "source": [
    "xTensor = torch.from_numpy(X_fullTraining).float()\n",
    "yTensor = torch.Tensor(Y_fullTraining).float()\n",
    "\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output, hidden = RNN(xTensor)\n",
    "    loss = criterion(output.reshape(-1), yTensor.view(-1))\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, 100), end=' ')\n",
    "        print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96428f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_error(pred, actual):\n",
    "    return abs(pred - actual)/pred\n",
    "\n",
    "def plotNoiselessGraphs(output_1,output_2,output_3,output_4,Y_main,Y_plot,XAxis_date,date_pred,\n",
    "    set1_title_1,set2_title_1,set3_title_1,set4_title_1,error_title):\n",
    "    \n",
    "    table = []\n",
    "\n",
    "    error = prediction_error(output_1, Y_main)\n",
    "    error_dt = pd.DataFrame(data = error)\n",
    "    temp1 = [np.mean(error), np.std(error), error_dt.skew(axis=0).iloc[0], error_dt.kurtosis(axis=0).iloc[0]]\n",
    "    temp1 = np.array(temp1)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.set_title(set1_title_1)\n",
    "    ax1.plot(date_pred, output_1, color = 'blue', label = 'Pred')\n",
    "    ax1.plot(XAxis_date, Y_plot, color = 'green', label = 'Actual')\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.set_title(error_title)\n",
    "    ax2.plot(date_pred, error, color = 'red', label = 'Pred error')\n",
    "    ax2.legend(loc=\"upper left\")\n",
    "\n",
    "    error = prediction_error(output_2, Y_main)\n",
    "    error_dt = pd.DataFrame(data = error)\n",
    "    temp2 = [np.mean(error), np.std(error), error_dt.skew(axis=0).iloc[0], error_dt.kurtosis(axis=0).iloc[0]]\n",
    "    temp2 = np.array(temp2)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.set_title(set2_title_1)\n",
    "    ax1.plot(date_pred, output_2, color = 'blue', label = 'Pred')\n",
    "    ax1.plot(XAxis_date, Y_plot, color = 'green', label = 'Actual')\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.set_title(error_title)\n",
    "    ax2.plot(date_pred, error, color = 'red', label = 'Pred error')\n",
    "    ax2.legend(loc=\"upper left\")\n",
    "\n",
    "    error = prediction_error(output_3, Y_main)\n",
    "    error_dt = pd.DataFrame(data = error)\n",
    "    temp3 = [np.mean(error), np.std(error), error_dt.skew(axis=0).iloc[0], error_dt.kurtosis(axis=0).iloc[0]]\n",
    "    temp3 = np.array(temp3)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.set_title(set3_title_1)\n",
    "    ax1.plot(date_pred, output_3, color = 'blue', label = 'Pred')\n",
    "    ax1.plot(XAxis_date, Y_plot, color = 'green', label = 'Actual')\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.set_title(error_title)\n",
    "    ax2.plot(date_pred, error, color = 'red', label = 'Pred error')\n",
    "    ax2.legend(loc=\"upper left\")\n",
    "\n",
    "    error = prediction_error(output_4, Y_main)\n",
    "    error_dt = pd.DataFrame(data = error)\n",
    "    temp4 = [np.mean(error), np.std(error), error_dt.skew(axis=0).iloc[0], error_dt.kurtosis(axis=0).iloc[0]]\n",
    "    temp4 = np.array(temp4)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    ax1.set_title(set4_title_1)\n",
    "    ax1.plot(date_pred, output_plt4, color = 'blue', label = 'Pred')\n",
    "    ax1.plot(XAxis_date, Y_plot, color = 'green', label = 'Actual')\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "    ax2.set_title(error_title)\n",
    "    ax2.plot(date_pred, error, color = 'red', label = 'Pred error')\n",
    "    ax2.legend(loc=\"upper left\")\n",
    "\n",
    "    temp1 = np.expand_dims(temp1, axis=1)\n",
    "    temp2 = np.expand_dims(temp2, axis=1)\n",
    "    temp3 = np.expand_dims(temp3, axis=1)\n",
    "    temp4 = np.expand_dims(temp4, axis=1)\n",
    "    table = np.concatenate((temp1, temp2, temp3, temp4), axis=1)\n",
    "    ind = ['Mean', 'STD-dev', 'Skewness', 'Kurtosis']\n",
    "    col = ['1 day', '2 day', '3 day', '4 day']\n",
    "    stats=pd.DataFrame(table, columns=col, index=ind).T\n",
    "    stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae68e7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_plt1 = output.detach().numpy()[:, 0]\n",
    "output_plt1 = norm.inverse_transform(output_plt1.reshape(-1,1))\n",
    "\n",
    "output_plt2 = output.detach().numpy()[:, 1]\n",
    "output_plt2 = norm.inverse_transform(output_plt2.reshape(-1,1))\n",
    "\n",
    "output_plt3 = output.detach().numpy()[:, 2]\n",
    "output_plt3 = norm.inverse_transform(output_plt3.reshape(-1,1))\n",
    "\n",
    "output_plt4 = output.detach().numpy()[:, 3]\n",
    "output_plt4 = norm.inverse_transform(output_plt4.reshape(-1,1))\n",
    "\n",
    "Y_plt = norm.inverse_transform(Y[:, :, 0])\n",
    "Y_fullTrainingplt = norm.inverse_transform(Y_fullTraining[:, :, 0])\n",
    "\n",
    "plotNoiselessGraphs(output_plt1,output_plt2,output_plt3,output_plt4,Y_fullTrainingplt,Y_plt,dateAxis,date_ft,\n",
    "\"Full Training Set (1 day)\",\"Full Training Set (2 day)\",\"Full Training Set (3 day)\",\"Full Training Set (4 day)\",\"Error of Training Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a864bd3f",
   "metadata": {},
   "source": [
    "# Step 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce6141",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN.eval()\n",
    "xTensor = torch.from_numpy(X_test).float()\n",
    "output, _ = RNN(xTensor)\n",
    "\n",
    "output_plt1 = output.detach().numpy()[:, 0]\n",
    "output_plt1 = norm.inverse_transform(output_plt1.reshape(-1,1))\n",
    "\n",
    "output_plt2 = output.detach().numpy()[:, 1]\n",
    "output_plt2 = norm.inverse_transform(output_plt2.reshape(-1,1))\n",
    "\n",
    "output_plt3 = output.detach().numpy()[:, 2]\n",
    "output_plt3 = norm.inverse_transform(output_plt3.reshape(-1,1))\n",
    "\n",
    "output_plt4 = output.detach().numpy()[:, 3]\n",
    "output_plt4 = norm.inverse_transform(output_plt4.reshape(-1,1))\n",
    "\n",
    "Y_testplt = norm.inverse_transform(Y_test[:, :, 0])\n",
    "\n",
    "plotNoiselessGraphs(output_plt1,output_plt2,output_plt3,output_plt4,Y_testplt,Y_plt,dateAxis,date_t,\n",
    "\"Test Set (1 day)\",\"Test Set (2 day)\",\"Test Set (3 day)\",\"Test Set (4 day)\",\"Error of Test Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deed342",
   "metadata": {},
   "source": [
    "# Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9124d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNval = Model(input_size=3, output_size=4, hidden_dim=32, n_layers=2)\n",
    "optimizerVal = torch.optim.Adam(RNNval.parameters(), lr=0.002)\n",
    "criterionVal = nn.MSELoss()\n",
    "RNNval\n",
    "\n",
    "xTensor = torch.from_numpy(X_training).float()\n",
    "yTensor = torch.Tensor(Y_training).float()\n",
    "\n",
    "for epoch in range(200):\n",
    "    optimizerVal.zero_grad()\n",
    "    \n",
    "    output, hidden = RNNval(xTensor)\n",
    "    loss = criterionVal(output.reshape(-1), yTensor.view(-1))\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizerVal.step()\n",
    "    \n",
    "    if epoch%100 == 0:\n",
    "        print('Epoch: {}/{}.............'.format(epoch, 200), end=' ')\n",
    "        print(\"Loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc5d9e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output_plt1 = output.detach().numpy()[:, 0]\n",
    "output_plt1 = norm.inverse_transform(output_plt1.reshape(-1,1))\n",
    "\n",
    "output_plt2 = output.detach().numpy()[:, 1]\n",
    "output_plt2 = norm.inverse_transform(output_plt2.reshape(-1,1))\n",
    "\n",
    "output_plt3 = output.detach().numpy()[:, 2]\n",
    "output_plt3 = norm.inverse_transform(output_plt3.reshape(-1,1))\n",
    "\n",
    "output_plt4 = output.detach().numpy()[:, 3]\n",
    "output_plt4 = norm.inverse_transform(output_plt4.reshape(-1,1))\n",
    "\n",
    "Y_plt = norm.inverse_transform(Y[:, :, 0])\n",
    "Y_trainingplt = norm.inverse_transform(Y_training[:, :, 0])\n",
    "\n",
    "plotNoiselessGraphs(output_plt1,output_plt2,output_plt3,output_plt4,Y_trainingplt,Y_plt,dateAxis,date_tr,\n",
    "\"Training Set (1 day)\",\"Training Set (2 day)\",\"Training Set (3 day)\",\"Training Set (4 day)\",\"Error of Training Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71349bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNNval.eval()\n",
    "xTensor = torch.from_numpy(X_validation).float()\n",
    "output, _ = RNNval(xTensor)\n",
    "\n",
    "output_plt1 = output.detach().numpy()[:, 0]\n",
    "output_plt1 = norm.inverse_transform(output_plt1.reshape(-1,1))\n",
    "\n",
    "output_plt2 = output.detach().numpy()[:, 1]\n",
    "output_plt2 = norm.inverse_transform(output_plt2.reshape(-1,1))\n",
    "\n",
    "output_plt3 = output.detach().numpy()[:, 2]\n",
    "output_plt3 = norm.inverse_transform(output_plt3.reshape(-1,1))\n",
    "\n",
    "output_plt4 = output.detach().numpy()[:, 3]\n",
    "output_plt4 = norm.inverse_transform(output_plt4.reshape(-1,1))\n",
    "\n",
    "Y_validationplt = norm.inverse_transform(Y_validation[:, :, 0])\n",
    "\n",
    "plotNoiselessGraphs(output_plt1,output_plt2,output_plt3,output_plt4,Y_validationplt,Y_plt,dateAxis,date_v,\n",
    "\"Validation Set (1 day)\",\"Validation Set (2 day)\",\"Validation Set (3 day)\",\"Validation Set (4 day)\",\"Error of Validation Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388d7e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "xTensor = torch.from_numpy(X_test).float()\n",
    "output, _ = RNNval(xTensor)\n",
    "\n",
    "output_plt1 = output.detach().numpy()[:, 0]\n",
    "output_plt1 = norm.inverse_transform(output_plt1.reshape(-1,1))\n",
    "\n",
    "output_plt2 = output.detach().numpy()[:, 1]\n",
    "output_plt2 = norm.inverse_transform(output_plt2.reshape(-1,1))\n",
    "\n",
    "output_plt3 = output.detach().numpy()[:, 2]\n",
    "output_plt3 = norm.inverse_transform(output_plt3.reshape(-1,1))\n",
    "\n",
    "output_plt4 = output.detach().numpy()[:, 3]\n",
    "output_plt4 = norm.inverse_transform(output_plt4.reshape(-1,1))\n",
    "\n",
    "Y_testplt = norm.inverse_transform(Y_test[:, :, 0])\n",
    "\n",
    "plotNoiselessGraphs(output_plt1,output_plt2,output_plt3,output_plt4,Y_testplt,Y_plt,dateAxis,date_t,\n",
    "\"Test Set (1 day)\",\"Test Set (2 day)\",\"Test Set (3 day)\",\"Test Set (4 day)\",\"Error of Test Set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85cc5b5",
   "metadata": {},
   "source": [
    "# Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0d8ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(day_index):\n",
    "    out_temp = np.concatenate( (Y_test[:, :, day_index], Y_test[:, :, day_index], Y_test[:, :, day_index]), axis = 1)\n",
    "    target = norm.inverse_transform(out_temp)[:, [0]]\n",
    "    error_res_all = []\n",
    "    for sigma in stdev:\n",
    "        noisy_data = NoisyTesting(X_test, sigma)\n",
    "        inputs = Variable(torch.from_numpy(noisy_data).float())\n",
    "        output, _ = RNNval(inputs)\n",
    "        out_temp = np.concatenate((output.detach().numpy()[:, [day_index]], \n",
    "                                   output.detach().numpy()[:, [day_index]],  \n",
    "                                   output.detach().numpy()[:, [day_index]]), axis=1)\n",
    "        predicted_price = norm.inverse_transform(out_temp)[:, [0]]\n",
    "        error = prediction_error(target, predicted_price)\n",
    "        error_res_all.append(error.reshape(-1))\n",
    "    return error_res_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896ae08a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cmaps= ['red','purple', 'green', 'orange',  'yellow', 'pink', 'grey', 'brown', 'black','blue' ]\n",
    "def FullGraphing(day):\n",
    "    plt.figure(1, figsize=(15, 5))\n",
    "    for i in range(len(stdev)): \n",
    "        #print(np.shape(date_test))\n",
    "        #print(np.shape(error_res_all[i]))\n",
    "        #print(np.shape(cmaps[i]))\n",
    "        plt.plot(np.squeeze(date_test), error_res_all[i], color=cmaps[i], lw=1, label = stdev[i], marker= 'o', linestyle='None')  \n",
    "\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Prediction error')\n",
    "    plt.title('Prediction error with Different Noise Levels (next ' +day+ ' day)')\n",
    "    plt.legend(loc=\"lower right\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae6ba8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def IndividualGraphing(day):\n",
    "    for i in range(len(stdev)): \n",
    "        plt.figure(1, figsize=(15, 5))\n",
    "        plt.plot(np.squeeze(date_test), error_res_all[i], color=cmaps[i], lw=1, label = stdev[i], marker= 'o', linestyle='None')  \n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Prediction error')\n",
    "        plt.title('Prediction error with Different Noise Levels (next '+day+' day)')\n",
    "        plt.legend(loc=\"lower right\")  \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2862315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOISY\n"
     ]
    }
   ],
   "source": [
    "print(\"NOISY\")\n",
    "stdev = [0,0.001, 0.002, 0.003, 0.005, 0.01, 0.02, 0.03, 0.05,0.1]\n",
    "\n",
    "def NoisyTesting(dataset, sigma):\n",
    "    noisy_data = np.ndarray(shape=dataset.shape, dtype=np.float32)\n",
    "    #set seed for random numbers\n",
    "    random.seed(1)\n",
    "    for i in range(6):\n",
    "        s = np.random.normal(0, sigma, 20)\n",
    "        index = random.sample(list(range(180)), 20)\n",
    "        noisy_data[i] = dataset[i]\n",
    "        noisy_data[index, i, 0] = noisy_data[index, i, 0] + s\n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52906f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_res_all=predict(0)\n",
    "\n",
    "labels = date_test[:,0]\n",
    "df_error=pd.DataFrame(error_res_all, columns=labels, index=stdev).T\n",
    "display(df_error)\n",
    "\n",
    "FullGraphing(\"one\")\n",
    "IndividualGraphing(\"one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cde8870",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_res_all=predict(1)\n",
    "\n",
    "output.detach().numpy()[:,0:1]\n",
    "df_error=pd.DataFrame(error_res_all, columns=labels, index=stdev).T\n",
    "display(df_error)\n",
    "\n",
    "FullGraphing(\"two\")\n",
    "IndividualGraphing(\"two\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef94d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_res_all=predict(2)\n",
    "\n",
    "output.detach().numpy()[:,0:2]\n",
    "df_error=pd.DataFrame(error_res_all, columns=labels, index=stdev).T\n",
    "display(df_error)\n",
    "\n",
    "FullGraphing(\"three\")\n",
    "IndividualGraphing(\"three\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7157414",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_res_all=predict(3)\n",
    "\n",
    "output.detach().numpy()[:,0:3]\n",
    "df_error=pd.DataFrame(error_res_all, columns=labels, index=stdev).T\n",
    "display(df_error)\n",
    "\n",
    "FullGraphing(\"four\")\n",
    "IndividualGraphing(\"four\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
